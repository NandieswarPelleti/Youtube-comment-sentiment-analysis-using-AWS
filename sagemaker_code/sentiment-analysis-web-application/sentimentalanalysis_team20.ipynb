{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %mkdir ../data\n",
    "# !wget -O ../data/aclImdb_v1.tar.gz http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "# !tar -zxf ../data/aclImdb_v1.tar.gz -C ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def read_imdb_data(data_dir='../data/aclImdb'):\n",
    "    data = {}\n",
    "    labels = {}\n",
    "    \n",
    "    for data_type in ['train', 'test']:\n",
    "        data[data_type] = {}\n",
    "        labels[data_type] = {}\n",
    "        \n",
    "        for sentiment in ['pos', 'neg']:\n",
    "            data[data_type][sentiment] = []\n",
    "            labels[data_type][sentiment] = []\n",
    "            \n",
    "            path = os.path.join(data_dir, data_type, sentiment, '*.txt')\n",
    "            files = glob.glob(path)\n",
    "            \n",
    "            for f in files:\n",
    "                with open(f) as review:\n",
    "                    data[data_type][sentiment].append(review.read())\n",
    "                    labels[data_type][sentiment].append(1 if sentiment == 'pos' else 0)\n",
    "                    \n",
    "            assert len(data[data_type][sentiment]) == len(labels[data_type][sentiment]), \\\n",
    "                    \"{}/{} data size does not match labels size\".format(data_type, sentiment)\n",
    "                \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB reviews: train = 12500 pos / 12500 neg, test = 12500 pos / 12500 neg\n"
     ]
    }
   ],
   "source": [
    "data, labels = read_imdb_data()\n",
    "print(\"IMDB reviews: train = {} pos / {} neg, test = {} pos / {} neg\".format(\n",
    "            len(data['train']['pos']), len(data['train']['neg']),\n",
    "            len(data['test']['pos']), len(data['test']['neg'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def prepare_imdb_data(data, labels):\n",
    "    data_train = data['train']['pos'] + data['train']['neg']\n",
    "    data_test = data['test']['pos'] + data['test']['neg']\n",
    "    labels_train = labels['train']['pos'] + labels['train']['neg']\n",
    "    labels_test = labels['test']['pos'] + labels['test']['neg']\n",
    "    \n",
    "    data_train, labels_train = shuffle(data_train, labels_train)\n",
    "    data_test, labels_test = shuffle(data_test, labels_test)\n",
    "    \n",
    "    return data_train, data_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDb reviews (combined): train = 25000, test = 25000\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = prepare_imdb_data(data, labels)\n",
    "print(\"IMDb reviews (combined): train = {}, test = {}\".format(len(train_X), len(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my favorite of the three care bears movies. Once again I liked all the songs. The big problem however as most people have pointed out was that this story contradicts the original. For those that saw the first movie recall the bears met their \"cousins\" who they apparently never knew about. It wasn't of course until the end that the cousins received their tummy symbols after proving how much they cared. In this story however the cousins grow up with the care bears and have tummy symbols all along. That being said this isn't a bad movie as long you keep it separate from the first. I thought the Darkheart character much more evil then the Nicholas of the first. But at the same time I felt it added a sort of balance to the sweetness of the care bears. I also liked the we care part at the end, although I know other people had mixed feelings about that scene. And of course I LOVED the songs. My favorites being Growing Up and Forever Young. The care bears movies have always had such good songs. Ten stars for a very good movie.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(train_X[100])\n",
    "print(train_y[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X[100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk) (4.66.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def review_to_words(review):\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    text = BeautifulSoup(review, \"html.parser\").get_text() \n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) \n",
    "    words = text.split() \n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")] \n",
    "    words = [PorterStemmer().stem(w) for w in words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['favorit',\n",
       " 'three',\n",
       " 'care',\n",
       " 'bear',\n",
       " 'movi',\n",
       " 'like',\n",
       " 'song',\n",
       " 'big',\n",
       " 'problem',\n",
       " 'howev',\n",
       " 'peopl',\n",
       " 'point',\n",
       " 'stori',\n",
       " 'contradict',\n",
       " 'origin',\n",
       " 'saw',\n",
       " 'first',\n",
       " 'movi',\n",
       " 'recal',\n",
       " 'bear',\n",
       " 'met',\n",
       " 'cousin',\n",
       " 'appar',\n",
       " 'never',\n",
       " 'knew',\n",
       " 'cours',\n",
       " 'end',\n",
       " 'cousin',\n",
       " 'receiv',\n",
       " 'tummi',\n",
       " 'symbol',\n",
       " 'prove',\n",
       " 'much',\n",
       " 'care',\n",
       " 'stori',\n",
       " 'howev',\n",
       " 'cousin',\n",
       " 'grow',\n",
       " 'care',\n",
       " 'bear',\n",
       " 'tummi',\n",
       " 'symbol',\n",
       " 'along',\n",
       " 'said',\n",
       " 'bad',\n",
       " 'movi',\n",
       " 'long',\n",
       " 'keep',\n",
       " 'separ',\n",
       " 'first',\n",
       " 'thought',\n",
       " 'darkheart',\n",
       " 'charact',\n",
       " 'much',\n",
       " 'evil',\n",
       " 'nichola',\n",
       " 'first',\n",
       " 'time',\n",
       " 'felt',\n",
       " 'ad',\n",
       " 'sort',\n",
       " 'balanc',\n",
       " 'sweet',\n",
       " 'care',\n",
       " 'bear',\n",
       " 'also',\n",
       " 'like',\n",
       " 'care',\n",
       " 'part',\n",
       " 'end',\n",
       " 'although',\n",
       " 'know',\n",
       " 'peopl',\n",
       " 'mix',\n",
       " 'feel',\n",
       " 'scene',\n",
       " 'cours',\n",
       " 'love',\n",
       " 'song',\n",
       " 'favorit',\n",
       " 'grow',\n",
       " 'forev',\n",
       " 'young',\n",
       " 'care',\n",
       " 'bear',\n",
       " 'movi',\n",
       " 'alway',\n",
       " 'good',\n",
       " 'song',\n",
       " 'ten',\n",
       " 'star',\n",
       " 'good',\n",
       " 'movi']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_to_words(train_X[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "cache_dir = os.path.join(\"../cache\", \"sentiment_analysis\")  \n",
    "os.makedirs(cache_dir, exist_ok=True) \n",
    "def preprocess_data(data_train, data_test, labels_train, labels_test,\n",
    "                    cache_dir=cache_dir, cache_file=\"preprocessed_data.pkl\"):\n",
    "\n",
    "    cache_data = None\n",
    "    if cache_file is not None:\n",
    "        try:\n",
    "            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
    "                cache_data = pickle.load(f)\n",
    "            print(\"Read preprocessed data from cache file:\", cache_file)\n",
    "        except:\n",
    "            pass \n",
    "    \n",
    "    if cache_data is None:\n",
    "        words_train = [review_to_words(review) for review in data_train]\n",
    "        words_test = [review_to_words(review) for review in data_test]\n",
    "        \n",
    "        if cache_file is not None:\n",
    "            cache_data = dict(words_train=words_train, words_test=words_test,\n",
    "                              labels_train=labels_train, labels_test=labels_test)\n",
    "            with open(os.path.join(cache_dir, cache_file), \"wb\") as f:\n",
    "                pickle.dump(cache_data, f)\n",
    "            print(\"Wrote preprocessed data to cache file:\", cache_file)\n",
    "    else:\n",
    "        words_train, words_test, labels_train, labels_test = (cache_data['words_train'],\n",
    "                cache_data['words_test'], cache_data['labels_train'], cache_data['labels_test'])\n",
    "    \n",
    "    return words_train, words_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read preprocessed data from cache file: preprocessed_data.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_X, test_X, train_y, test_y = preprocess_data(train_X, test_X, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_dict(data, vocab_size = 5000):\n",
    "    word_count = {} \n",
    "    \n",
    "    for item in data:\n",
    "        for word in item:\n",
    "            if word not in word_count:\n",
    "                word_count[word] = 1\n",
    "            else:\n",
    "                word_count[word] +=1\n",
    "\n",
    "    sorted_words = sorted(word_count, key=word_count.get, reverse=True)\n",
    "    \n",
    "    word_dict = {} \n",
    "    for idx, word in enumerate(sorted_words[:vocab_size - 2]): \n",
    "        word_dict[word] = idx + 2                             \n",
    "        \n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = build_dict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/pytorch'\n",
    "if not os.path.exists(data_dir): \n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'word_dict.pkl'), \"wb\") as f:\n",
    "    pickle.dump(word_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_pad(word_dict, sentence, pad=500):\n",
    "    NOWORD = 0 \n",
    "    INFREQ = 1 \n",
    "    working_sentence = [NOWORD] * pad\n",
    "    for word_index, word in enumerate(sentence[:pad]):\n",
    "        if word in word_dict:\n",
    "            working_sentence[word_index] = word_dict[word]\n",
    "        else:\n",
    "            working_sentence[word_index] = INFREQ\n",
    "            \n",
    "    return working_sentence, min(len(sentence), pad)\n",
    "def convert_and_pad_data(word_dict, data, pad=500):\n",
    "    result = []\n",
    "    lengths = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        converted, leng = convert_and_pad(word_dict, sentence, pad)\n",
    "        result.append(converted)\n",
    "        lengths.append(leng)\n",
    "        \n",
    "    return np.array(result), np.array(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_X_len = convert_and_pad_data(word_dict, train_X)\n",
    "test_X, test_X_len = convert_and_pad_data(word_dict, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 591  573   46   23  512 1016 2043 1573 2681  174    2  562   21 4967\n",
      "   90    3  311   11   79  132 1422   47    2  172 2251   12 2310 1573\n",
      " 2681    2   59 1573 2681    2  311  184  113  685  822  728    3 1016\n",
      " 2043 3204 1386 1310   30   59 1573 2681  371    3 1239  793   33   17\n",
      "    1 1205  404 2956 2681    2  178    5    4    3   14  848 3185    1\n",
      " 1994    1  871 2043  177   43   36  129 2750 1442    1  265    3   57\n",
      "   98   28  145  881  416  523 1573 2681 4641  331  822   28 2681 2681\n",
      " 1455  167  822   87  366  228 2681   37  139   93  256    2   47   28\n",
      "    3  197   76 4781 2886  220   37  822  517  129 1292   42    3  368\n",
      "  509   33 1534   93  169    3  704 1121    1 1633  890   13  117 2681\n",
      "  459  193  881  249  416   90   28  648  144  179 3671  958  108    1\n",
      "   22    2  573 3642   45   64  606   61  887   92   39 1101 2043 1311\n",
      "    1  881   23  149  521 3281  571   22   28 1016 2043   22   14 1849\n",
      " 3281  146  584 2714  909 1016 2043    1    1    8  196  495  152 1719\n",
      "    4  128    1 1573 2681   33 2371  339 4448   17 2681  123  142    5\n",
      "  348  121   62 2327 1774  330    1   17   30  296   56  381 2681   97\n",
      "  822    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "225\n"
     ]
    }
   ],
   "source": [
    "print(train_X[100])\n",
    "print(train_X_len[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "    \n",
    "pd.concat([pd.DataFrame(train_y), pd.DataFrame(train_X_len), pd.DataFrame(train_X)], axis=1) \\\n",
    "        .to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/sentiment_rnn'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mLSTMClassifier\u001b[39;49;00m(nn.Module):\u001b[37m\u001b[39;49;00m\r\n",
      "  \u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, embedding_dim, hidden_dim, vocab_size):\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[36msuper\u001b[39;49;00m(LSTMClassifier, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[36mself\u001b[39;49;00m.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[36mself\u001b[39;49;00m.lstm = nn.LSTM(embedding_dim, hidden_dim)\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[36mself\u001b[39;49;00m.dense = nn.Linear(in_features=hidden_dim, out_features=\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[36mself\u001b[39;49;00m.sig = nn.Sigmoid()\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[36mself\u001b[39;49;00m.word_dict = \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[37m\u001b[39;49;00m\r\n",
      "        x = x.t()\u001b[37m\u001b[39;49;00m\r\n",
      "        lengths = x[\u001b[34m0\u001b[39;49;00m,:]\u001b[37m\u001b[39;49;00m\r\n",
      "        reviews = x[\u001b[34m1\u001b[39;49;00m:,:]\u001b[37m\u001b[39;49;00m\r\n",
      "        embeds = \u001b[36mself\u001b[39;49;00m.embedding(reviews)\u001b[37m\u001b[39;49;00m\r\n",
      "        lstm_out, _ = \u001b[36mself\u001b[39;49;00m.lstm(embeds)\u001b[37m\u001b[39;49;00m\r\n",
      "        out = \u001b[36mself\u001b[39;49;00m.dense(lstm_out)\u001b[37m\u001b[39;49;00m\r\n",
      "        out = out[lengths - \u001b[34m1\u001b[39;49;00m, \u001b[36mrange\u001b[39;49;00m(\u001b[36mlen\u001b[39;49;00m(lengths))]\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.sig(out.squeeze())\u001b[37m\u001b[39;49;00m\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize train/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.16.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Collecting torch==2.1.1 (from torchvision)\n",
      "  Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (3.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.1.1->torchvision) (2023.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.1->torchvision)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.1->torchvision)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.1->torchvision)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.1->torchvision)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.1->torchvision)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m830.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.1->torchvision)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.1->torchvision)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.1->torchvision)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.1->torchvision)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.1->torchvision)\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.1->torchvision)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.1.0 (from torch==2.1.1->torchvision)\n",
      "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.1->torchvision)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch==2.1.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch==2.1.1->torchvision) (1.3.0)\n",
      "Downloading torchvision-0.16.1-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m567.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m536.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.1.1 torchvision-0.16.1 triton-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "train_sample = pd.read_csv(os.path.join(data_dir, 'train.csv'), header=None, names=None, nrows=250)\n",
    "\n",
    "train_sample_y = torch.from_numpy(train_sample[[0]].values).float().squeeze()\n",
    "train_sample_X = torch.from_numpy(train_sample.drop([0], axis=1).values).long()\n",
    "\n",
    "train_sample_ds = torch.utils.data.TensorDataset(train_sample_X, train_sample_y)\n",
    "train_sample_dl = torch.utils.data.DataLoader(train_sample_ds, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs, optimizer, loss_fn, device):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:         \n",
    "            batch_X, batch_y = batch\n",
    "            \n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model.forward(batch_X)\n",
    "            loss = loss_fn(out, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.data.item()\n",
    "        print(\"Epoch: {}, BCELoss: {}\".format(epoch, total_loss / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 1, BCELoss: 0.6961587548255921\n",
      "Epoch: 2, BCELoss: 0.6857810974121094\n",
      "Epoch: 3, BCELoss: 0.6769315242767334\n",
      "Epoch: 4, BCELoss: 0.6673193216323853\n",
      "Epoch: 5, BCELoss: 0.6558300375938415\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from train.model import LSTMClassifier\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = LSTMClassifier(32, 100, 5000).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "train(model, train_sample_dl, 5, optimizer, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-12-13-18-21-37-175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2023-12-13 18:21:37 Starting - Starting the training job...\n",
      "2023-12-13 18:22:02 Starting - Preparing the instances for training............\n",
      "2023-12-13 18:23:59 Downloading - Downloading input data...\n",
      "2023-12-13 18:24:34 Downloading - Downloading the training image......\n",
      "2023-12-13 18:25:30 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-12-13 18:25:37,548 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-12-13 18:25:37,551 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-12-13 18:25:37,562 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-12-13 18:25:37,565 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-12-13 18:25:37,769 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.19.1)\u001b[0m\n",
      "\u001b[34mCollecting nltk\n",
      "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (4.10.0)\u001b[0m\n",
      "\u001b[34mCollecting html5lib\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->-r requirements.txt (line 1)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from nltk->-r requirements.txt (line 3)) (4.61.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk->-r requirements.txt (line 3)) (8.0.3)\u001b[0m\n",
      "\u001b[34mCollecting regex>=2021.8.3\n",
      "  Downloading regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk->-r requirements.txt (line 3)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.6/site-packages (from beautifulsoup4->-r requirements.txt (line 4)) (2.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.9 in /opt/conda/lib/python3.6/site-packages (from html5lib->-r requirements.txt (line 5)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: webencodings in /opt/conda/lib/python3.6/site-packages (from html5lib->-r requirements.txt (line 5)) (0.5.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from click->nltk->-r requirements.txt (line 3)) (4.8.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->click->nltk->-r requirements.txt (line 3)) (3.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->click->nltk->-r requirements.txt (line 3)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: regex, nltk, html5lib\u001b[0m\n",
      "\u001b[34mSuccessfully installed html5lib-1.1 nltk-3.6.7 regex-2023.8.8\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2023-12-13 18:25:42,654 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-12-13 18:25:42,670 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-12-13 18:25:42,683 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-12-13 18:25:42,696 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 20,\n",
      "        \"hidden_dim\": 200\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2023-12-13-18-21-37-175\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-541448256856/pytorch-training-2023-12-13-18-21-37-175/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m4.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m4.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":20,\"hidden_dim\":200}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-541448256856/pytorch-training-2023-12-13-18-21-37-175/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":20,\"hidden_dim\":200},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2023-12-13-18-21-37-175\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-541448256856/pytorch-training-2023-12-13-18-21-37-175/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"20\",\"--hidden_dim\",\"200\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=200\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --epochs 20 --hidden_dim 200\u001b[0m\n",
      "\u001b[34mUsing device cpu.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mModel loaded with embedding_dim 32, hidden_dim 200, vocab_size 5000.\u001b[0m\n",
      "\u001b[34m[2023-12-13 18:25:44.873 algo-1:34 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-12-13 18:25:45.096 algo-1:34 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-12-13 18:25:45.096 algo-1:34 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-12-13 18:25:45.097 algo-1:34 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-12-13 18:25:45.097 algo-1:34 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-12-13 18:25:45.098 algo-1:34 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2023-12-13 18:25:45.105 algo-1:34 INFO hook.py:591] name:weight count_params:160000\u001b[0m\n",
      "\u001b[34m[2023-12-13 18:25:45.105 algo-1:34 INFO hook.py:593] Total Trainable Params: 160000\u001b[0m\n",
      "\u001b[34m[2023-12-13 18:25:45.105 algo-1:34 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2023-12-13 18:25:45.108 algo-1:34 INFO hook.py:488] Hook is writing from the hook with pid: 34\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.6690408940217933\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.5850774889089623\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.5253639409736711\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.448875014271055\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.4460091006999113\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.38000536208250085\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.33870953078172644\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.3191174469432052\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.30293984133370067\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.2937456564027436\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.2821461080896611\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.25704940971063106\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.2449793216525292\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.23558637864735663\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.271874051313011\u001b[0m\n",
      "\u001b[34mEpoch: 16, BCELoss: 0.24400102818498806\u001b[0m\n",
      "\u001b[34mEpoch: 17, BCELoss: 0.19991839449016416\u001b[0m\n",
      "\u001b[34mEpoch: 18, BCELoss: 0.1902288554274306\u001b[0m\n",
      "\u001b[34mEpoch: 19, BCELoss: 0.18227853793270735\u001b[0m\n",
      "\n",
      "2023-12-13 19:47:44 Uploading - Uploading generated training model\u001b[34mEpoch: 20, BCELoss: 0.1737806419936978\u001b[0m\n",
      "\u001b[34m2023-12-13 19:47:39,893 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-12-13 19:48:00 Completed - Training job completed\n",
      "Training seconds: 5040\n",
      "Billable seconds: 5040\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"train.py\",\n",
    "                    source_dir=\"train\",\n",
    "                    role=role,\n",
    "                    framework_version='1.8.1', \n",
    "                    py_version=\"py3\",   \n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.m4.xlarge', \n",
    "                    hyperparameters={\n",
    "                        'epochs': 20,\n",
    "                        'hidden_dim': 200,\n",
    "                    })\n",
    "\n",
    "estimator.fit({'training': input_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:matplotlib.font_manager:generated new fontManager\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABqhUlEQVR4nO3dd1gU1/4G8Hd2WaqAgJRFaVZErGDBXiKixqiJN5bYNYklRqP+vBqTWK5JNDcx3hRJTCxRU02M0Vgxig07WFBsSFNABKRLn98fhI1I28VdBnbfz/PsE3fmzOz3MKu8mZlzRhBFUQQRERGRnpBJXQARERGRNjHcEBERkV5huCEiIiK9wnBDREREeoXhhoiIiPQKww0RERHpFYYbIiIi0isMN0RERKRXGG6IiIhIrzDcEFVBEAS1XsHBwc/0OcuXL4cgCDXaNjg4WCs1PMtn//rrr7X+2TVx5swZ/Otf/4JSqYSxsTGcnJwwatQonD59WurSyomOjq7yO7d8+XKpS4S7uzuef/55qcsgKsdI6gKI6rKnf+n95z//wdGjR3HkyJEyy728vJ7pc6ZPn46AgIAabdupUyecPn36mWvQd59//jnmzZuHLl264KOPPoKbmxtiY2Px5ZdfomfPnvjf//6HN954Q+oyy5kzZw7GjRtXbnmTJk0kqIaofmC4IapCt27dyry3t7eHTCYrt/xpOTk5MDc3V/tzmjRpUuNfVlZWVtXWY+hOnTqFefPmYciQIfj9999hZPTPP31jxozByJEjMXfuXHTs2BE9evSotboeP34MU1PTKs/aubq68vgSaYiXpYieUd++feHt7Y3jx4+je/fuMDc3x9SpUwEAP//8M/z9/aFUKmFmZobWrVtj8eLFyM7OLrOPii5LlZ7yP3DgADp16gQzMzN4enpi06ZNZdpVdFlq8uTJaNCgAe7cuYMhQ4agQYMGcHFxwYIFC5CXl1dm+3v37mHUqFGwtLREw4YN8corr+D8+fMQBAFbtmzRys8oPDwcw4cPh42NDUxNTdGhQwd89913ZdoUFxdj1apVaNWqFczMzNCwYUO0a9cO//vf/1RtHj58iNdeew0uLi4wMTGBvb09evTogcOHD1f5+R9++CEEQUBgYGCZYAMARkZGWL9+PQRBwOrVqwEAu3btgiAI+Ouvv8rtKzAwEIIg4MqVK6plFy5cwAsvvABbW1uYmpqiY8eO+OWXX8pst2XLFgiCgEOHDmHq1Kmwt7eHubl5ueNRE6XfwRMnTqBbt24wMzND48aN8e6776KoqKhM29TUVMyaNQuNGzeGsbExmjZtiqVLl5aro7i4GJ9//jk6dOigOh7dunXD7t27y31+dd/RnJwcLFy4EB4eHjA1NYWtrS18fX3x448/PnPfiSrCMzdEWpCQkIDx48dj0aJF+OCDDyCTlfx/w+3btzFkyBDMmzcPFhYWuHHjBtasWYNz586Vu7RVkcuXL2PBggVYvHgxHB0d8e2332LatGlo3rw5evfuXeW2BQUFeOGFFzBt2jQsWLAAx48fx3/+8x9YW1vjvffeAwBkZ2ejX79+SE1NxZo1a9C8eXMcOHAAo0ePfvYfyt9u3ryJ7t27w8HBAZ999hns7Oywfft2TJ48GQ8ePMCiRYsAAB999BGWL1+Od955B71790ZBQQFu3LiBtLQ01b4mTJiA0NBQvP/++2jZsiXS0tIQGhqKlJSUSj+/qKgIR48eha+vb6Vnx1xcXODj44MjR46gqKgIzz//PBwcHLB582YMGDCgTNstW7agU6dOaNeuHQDg6NGjCAgIQNeuXfHVV1/B2toaP/30E0aPHo2cnBxMnjy5zPZTp07F0KFDsW3bNmRnZ0OhUFT58ysuLkZhYWG55U+HtMTERIwZMwaLFy/GypUrsXfvXqxatQqPHj3CF198AQDIzc1Fv379EBkZiRUrVqBdu3Y4ceIEPvzwQ1y6dAl79+5V7W/y5MnYvn07pk2bhpUrV8LY2BihoaGIjo4u87nqfEfnz5+Pbdu2YdWqVejYsSOys7MRHh5e5XEjeiYiEalt0qRJooWFRZllffr0EQGIf/31V5XbFhcXiwUFBeKxY8dEAOLly5dV65YtWyY+/dfRzc1NNDU1FWNiYlTLHj9+LNra2oqvv/66atnRo0dFAOLRo0fL1AlA/OWXX8rsc8iQIWKrVq1U77/88ksRgLh///4y7V5//XURgLh58+Yq+1T62Tt27Ki0zZgxY0QTExMxNja2zPLBgweL5ubmYlpamiiKovj888+LHTp0qPLzGjRoIM6bN6/KNk9LTEwUAYhjxoypst3o0aNFAOKDBw9EURTF+fPni2ZmZqr6RFEUr1+/LgIQP//8c9UyT09PsWPHjmJBQUGZ/T3//POiUqkUi4qKRFEUxc2bN4sAxIkTJ6pVd1RUlAig0teJEydUbUu/g3/88UeZfbz66quiTCZTfYe++uqrCr8Xa9asEQGIhw4dEkVRFI8fPy4CEJcuXVpljep+R729vcURI0ao1W8ibeBlKSItsLGxQf/+/cstv3v3LsaNGwcnJyfI5XIoFAr06dMHABAREVHtfjt06ABXV1fVe1NTU7Rs2RIxMTHVbisIAoYNG1ZmWbt27cpse+zYMVhaWpa7mXns2LHV7l9dR44cwYABA+Di4lJm+eTJk5GTk6O6abtLly64fPkyZs2ahYMHDyIjI6Pcvrp06YItW7Zg1apVOHPmDAoKCrRWpyiKAKC6PDh16lQ8fvwYP//8s6rN5s2bYWJiorrB986dO7hx4wZeeeUVAEBhYaHqNWTIECQkJODmzZtlPuell17SqK65c+fi/Pnz5V4dOnQo087S0hIvvPBCmWXjxo1DcXExjh8/DqDkWFhYWGDUqFFl2pWeXSq9DLd//34AwOzZs6utT53vaJcuXbB//34sXrwYwcHBePz4sXqdJ6ohhhsiLVAqleWWZWVloVevXjh79ixWrVqF4OBgnD9/Hjt37gQAtf6Bt7OzK7fMxMRErW3Nzc1hampabtvc3FzV+5SUFDg6OpbbtqJlNZWSklLhz8fZ2Vm1HgCWLFmCjz/+GGfOnMHgwYNhZ2eHAQMG4MKFC6ptfv75Z0yaNAnffvst/Pz8YGtri4kTJyIxMbHSz2/UqBHMzc0RFRVVZZ3R0dEwNzeHra0tAKBNmzbo3LkzNm/eDKDk8tb27dsxfPhwVZsHDx4AABYuXAiFQlHmNWvWLABAcnJymc+p6GdRlSZNmsDX17fcq0GDBmXaVXTMnJycAPzzM05JSYGTk1O5+7scHBxgZGSkavfw4UPI5XLV9lVR5zv62Wef4d///jd27dqFfv36wdbWFiNGjMDt27er3T9RTTDcEGlBRaNdjhw5gvj4eGzatAnTp09H79694evrC0tLSwkqrJidnZ3qF/STqgoLNfmMhISEcsvj4+MBlIQPoOQekvnz5yM0NBSpqan48ccfERcXh0GDBiEnJ0fVdt26dYiOjkZMTAw+/PBD7Ny5s9x9LU+Sy+Xo168fLly4gHv37lXY5t69e7h48SL69+8PuVyuWj5lyhScOXMGEREROHDgABISEjBlyhTV+tLalyxZUuHZlYrOsNR0PqPqVHUcSwNI6fEuPUtVKikpCYWFhar+2Nvbo6ioSGvfAwsLC6xYsQI3btxAYmIiAgMDcebMmXJnFom0heGGSEdKf4mZmJiUWf71119LUU6F+vTpg8zMTNVliFI//fST1j5jwIABqqD3pK1bt8Lc3LzCYc4NGzbEqFGjMHv2bKSmppa7iRUoGSL9xhtvYODAgQgNDa2yhiVLlkAURcyaNavc6KGioiLMnDkToihiyZIlZdaNHTsWpqam2LJlC7Zs2YLGjRvD399ftb5Vq1Zo0aIFLl++XOHZldoMs5mZmeVGMv3www+QyWSqG3sHDBiArKws7Nq1q0y7rVu3qtYDwODBgwGUjAzTNkdHR0yePBljx47FzZs3VcGVSJs4WopIR7p37w4bGxvMmDEDy5Ytg0KhwPfff4/Lly9LXZrKpEmT8Omnn2L8+PFYtWoVmjdvjv379+PgwYMAoBr1VZ0zZ85UuLxPnz5YtmwZ/vzzT/Tr1w/vvfcebG1t8f3332Pv3r346KOPYG1tDQAYNmwYvL294evrC3t7e8TExGDdunVwc3NDixYtkJ6ejn79+mHcuHHw9PSEpaUlzp8/jwMHDuDFF1+ssr4ePXpg3bp1mDdvHnr27Ik33ngDrq6uqkn8zp49i3Xr1qF79+5ltmvYsCFGjhyJLVu2IC0tDQsXLiz3M/n6668xePBgDBo0CJMnT0bjxo2RmpqKiIgIhIaGYseOHWr9DCsTGxtb4c/X3t4ezZo1U723s7PDzJkzERsbi5YtW2Lfvn345ptvMHPmTNU9MRMnTsSXX36JSZMmITo6Gm3btsXJkyfxwQcfYMiQIXjuuecAAL169cKECROwatUqPHjwAM8//zxMTEwQFhYGc3NzzJkzR6M+dO3aFc8//zzatWsHGxsbREREYNu2bfDz89NoPigitUl7PzNR/VLZaKk2bdpU2D4kJET08/MTzc3NRXt7e3H69OliaGhouZFIlY2WGjp0aLl99unTR+zTp4/qfWWjpZ6us7LPiY2NFV988UWxQYMGoqWlpfjSSy+J+/btq3D0zdNKP7uyV2lNV69eFYcNGyZaW1uLxsbGYvv27cuNxPrkk0/E7t27i40aNRKNjY1FV1dXcdq0aWJ0dLQoiqKYm5srzpgxQ2zXrp1oZWUlmpmZia1atRKXLVsmZmdnV1lnqdOnT4ujRo0SHR0dRSMjI9HBwUF88cUXxZCQkEq3OXTokKo/t27dqrDN5cuXxZdffll0cHAQFQqF6OTkJPbv31/86quvVG1KR0udP39erVqrGy31yiuvqNqWfgeDg4NFX19f0cTERFQqleLbb79dbhRXSkqKOGPGDFGpVIpGRkaim5ubuGTJEjE3N7dMu6KiIvHTTz8Vvb29RWNjY9Ha2lr08/MT9+zZo2qj7nd08eLFoq+vr2hjYyOamJiITZs2Fd966y0xOTlZrZ8FkaYEUXzq4isRGbwPPvgA77zzDmJjYznNfz3Qt29fJCcnIzw8XOpSiOoEXpYiMnClE7x5enqioKAAR44cwWeffYbx48cz2BBRvcRwQ2TgzM3N8emnnyI6Ohp5eXlwdXXFv//9b7zzzjtSl0ZEVCO8LEVERER6hUPBiYiISK8w3BAREZFeYbghIiIivWJwNxQXFxcjPj4elpaWOpsGnYiIiLRLFEVkZmbC2dm52glGDS7cxMfHl3s6MREREdUPcXFx1U5TYXDhpvQ5L3FxcbCyspK4mtpRUFCAQ4cOwd/fHwqFQupyao2h9hsw3L4bar8B9t0Q+25o/c7IyICLi4taz2szuHBTeinKysrKoMKNubk5rKysDOIvQClD7TdguH031H4D7Lsh9t1Q+63OLSW8oZiIiIj0CsMNERER6RWGGyIiItIrDDdERESkVxhuiIiISK8w3BAREZFeYbghIiIivcJwQ0RERHqF4YaIiIj0isHNUKwrRcUizkWlIikzFw6WpujiYQu5jA/mJCIiqm0MN1pwIDwBK/ZcR0J6rmqZ0toUy4Z5IcBbKWFlREREhoeXpZ7RgfAEzNweWibYAEBiei5mbg/FgfAEiSojIiIyTAw3z6CoWMSKPdchVrCudNmKPddRVFxRCyIiItIFhptncC4qtdwZmyeJABLSc3EuKrX2iiIiIjJwDDfPICmz8mBTk3ZERET07BhunoGDpalW2xEREdGzY7h5Bl08bKG0NkVlA74FlIya6uJhW5tlERERGTSGm2cglwlYNswLACoNOMuGeXG+GyIiolrEcPOMAryVCBzfCU7W5S89rX6pHee5ISIiqmWcxE8LAryVGOjlpJqh+LO/biPyYTYSqxhJRURERLrBMzdaIpcJ8Gtmh+EdGuPNAS0AANvPxiC/sFjiyoiIiAwLw40ODGmrhKOVCR5m5mHv1XipyyEiIjIoDDc6oJDLML6rGwBg86loiCJnKCYiIqotDDc6Mq6rK4yNZLhyLx2hsWlSl0NERGQwGG50xK6BCYa3dwYAbAmJlrYYIiIiA8Jwo0OTe7gDAPZfTeDIKSIiolrCcKNDbZyt0cXDFoXFIradiZa6HCIiIoPAcKNjU/8+e/PD2VjkFhRJWwwREZEBYLjRsedaO6JxQzM8yinA7kscFk5ERKRrDDc6ZiSXYaJfybDwTaeiOCyciIhIxxhuasGYzq4wU8hxIzETZ6NSpS6HiIhIrzHc1AJrcwVGdmoMANh8KkriaoiIiPQbw00tmdLdHQAQdP0B4lJzpC2GiIhIjzHc1JIWjpbo1aIRikVg25kYqcshIiLSWww3tWjy32dvfjoXi5z8QmmLISIi0lMMN7WoXysHuNuZIyO3EL+F3pe6HCIiIr3EcFOLZDIBk/4+e7OFw8KJiIh0guGmlo3yaYIGJkaIfJiNE7eTpS6HiIhI7zDc1DJLUwVG+TQBwKeFExER6QLDjQQmd3eHIABHbiQhKjlb6nKIiIj0CsONBNwbWaBfKwcAwHc8e0NERKRVDDcSmfL308J3XIhDZm6BtMUQERHpEYYbifRs3gjNHRogO78IOy7ck7ocIiIivcFwIxFBEFST+n13OhpFxRwWTkREpA0MNxJ6sVNjWJkaISYlB8E3k6Quh4iISC8w3EjI3NgIY7q4AgA2n4qWthgiIiI9wXAjsYl+bpAJwMk7ybj1IFPqcoiIiOo9hhuJNbExh7+XEwBO6kdERKQNDDd1wOS/h4XvDL2HtJx8aYshIiKq5xhu6oCuHrZorbRCbkExfjofJ3U5RERE9RrDTR0gCIJqUr9tp2NQWFQsbUFERET1GMNNHfFCe2fYWhjjftpjBF1/IHU5RERE9RbDTR1hqpBjXOmwcN5YTEREVGMMN3XI+G5uMJIJOBeVimvx6VKXQ0REVC8x3NQhTtamGNxWCYCT+hEREdUUw00dU3pj8e5L8UjOypO2GCIionqI4aaO6eRqg/YuDZFfVIwfz8ZKXQ4REVG9I3m4Wb9+PTw8PGBqagofHx+cOHGiyvZ5eXlYunQp3NzcYGJigmbNmmHTpk21VG3tmPL308K3nYlBfiGHhRMREWlC0nDz888/Y968eVi6dCnCwsLQq1cvDB48GLGxlZ+xePnll/HXX39h48aNuHnzJn788Ud4enrWYtW6N6StEg6WJkjKzMP+8ASpyyEiIqpXJA03a9euxbRp0zB9+nS0bt0a69atg4uLCwIDAytsf+DAARw7dgz79u3Dc889B3d3d3Tp0gXdu3ev5cp1y9hIhvHd3ADwxmIiIiJNSRZu8vPzcfHiRfj7+5dZ7u/vj5CQkAq32b17N3x9ffHRRx+hcePGaNmyJRYuXIjHjx/XRsm1amwXVxjLZbgUl4aw2EdSl0NERFRvGEn1wcnJySgqKoKjo2OZ5Y6OjkhMTKxwm7t37+LkyZMwNTXF77//juTkZMyaNQupqamV3neTl5eHvLx/Rh1lZGQAAAoKClBQUKCl3mhfQ1MZhrZzwu9h8dh08i7W/qtdjfdV2s+63F9dMNR+A4bbd0PtN8C+P/lfQ2Fo/dakn5KFm1KCIJR5L4piuWWliouLIQgCvv/+e1hbWwMoubQ1atQofPnllzAzMyu3zYcffogVK1aUW37o0CGYm5troQe606wQAIyw92oCOivuwdr42fYXFBSkjbLqHUPtN2C4fTfUfgPsuyEylH7n5OSo3VaycNOoUSPI5fJyZ2mSkpLKnc0ppVQq0bhxY1WwAYDWrVtDFEXcu3cPLVq0KLfNkiVLMH/+fNX7jIwMuLi4wN/fH1ZWVlrqje4EZ5zDhZg0PLBsibEDmtdoHwUFBQgKCsLAgQOhUCi0XGHdZaj9Bgy374bab4B9N8S+G1q/S6+8qEOycGNsbAwfHx8EBQVh5MiRquVBQUEYPnx4hdv06NEDO3bsQFZWFho0aAAAuHXrFmQyGZo0aVLhNiYmJjAxMSm3XKFQ1Isvw9SeTXEhJhQ/nb+HOQNawlQhr/G+6kuftc1Q+w0Ybt8Ntd8A+26IfTeUfmvSR0lHS82fPx/ffvstNm3ahIiICLz11luIjY3FjBkzAJScdZk4caKq/bhx42BnZ4cpU6bg+vXrOH78OP7v//4PU6dOrfCSlD7w93KEs7UpUrLzsedyvNTlEBER1XmShpvRo0dj3bp1WLlyJTp06IDjx49j3759cHMrGQadkJBQZs6bBg0aICgoCGlpafD19cUrr7yCYcOG4bPPPpOqCzpnJJdhgp87AGBLSDREUZS2ICIiojpO8huKZ82ahVmzZlW4bsuWLeWWeXp6GszNU6XGdnHB//66hWvxGdgSEg1bC2M4WJqii4ct5LKKb74mIiIyVJKHG6peQ3Nj+LrZ4OSdFKzYc121XGltimXDvBDgrZSwOiIiorpF8mdLUfUOhCfg5J2UcssT03Mxc3soDvARDURERCoMN3VcUbFY5mzNk0rvvlmx5zqKinkvDhEREcBwU+edi0pFQnpupetFAAnpuTgXlVp7RREREdVhDDd1XFJm5cGmJu2IiIj0HcNNHedgaarVdkRERPqO4aaO6+JhC6W1KSob8C2gZNRUFw/b2iyLiIiozmK4qePkMgHLhnkBQIUBRwSwbJgX57shIiL6G8NNPRDgrUTg+E5wsi5/6clUIYOPG8/aEBERleIkfvVEgLcSA72ccC4qFUmZuWjUwAQf7otAeHwGPtwfgbUvd5C6RCIiojqBZ27qEblMgF8zOwzv0Bg9mjfCqpFtIQjAztD7OHO3/CR/REREhojhph7r4NIQ47q4AgDe+yMcBUXFEldEREQkPYabeu7/BrWCrYUxbj3IwuZTUVKXQ0REJDmGm3quobkxlgz2BACsO3wbCemPJa6IiIhIWgw3euClTk3g62aDnPwi/OfPip9DRUREZCgYbvSATCbgPyO8IZcJ2Hc1EcduPZS6JCIiIskw3OiJ1korTOnuDgBY9kc4cguKpC2IiIhIIgw3emTewJZwtDJBdEoOvj52V+pyiIiIJMFwo0camBjh3edLHtXwZfAdxKRkS1wRERFR7WO40TND2yrRs3kj5BcWY/nuaxBFUeqSiIiIahXDjZ4RBAErh7eBsVyGozcf4uC1B1KXREREVKsYbvRQU/sGeL1PUwDAyj3XkJNfKHFFREREtYfhRk/N6tscTWzMEJ+eiy+DeXMxEREZDoYbPWVmLMeKF9oAADadikFijsQFERER1RKGGz02oLUjnmvtiMJiETuiZLy5mIiIDILG4SY0NBRXr15Vvf/jjz8wYsQIvP3228jPz9dqcfTslg3zgqlChjsZMuy+kih1OURERDqncbh5/fXXcevWLQDA3bt3MWbMGJibm2PHjh1YtGiR1gukZ+Nia45Zf99cvPrATWTkFkhcERERkW5pHG5u3bqFDh06AAB27NiB3r1744cffsCWLVvw22+/abs+0oKpPdzhYCoiOSsfaw/dkrocIiIindI43IiiiOLiYgDA4cOHMWTIEACAi4sLkpOTtVsdaYWJkQyjmpYcs62noxF+P13iioiIiHRH43Dj6+uLVatWYdu2bTh27BiGDh0KAIiKioKjo6PWCyTtaGUtYmhbJxSLwDu7wlFczJuLiYhIP2kcbtatW4fQ0FC88cYbWLp0KZo3bw4A+PXXX9G9e3etF0jasySgJRqYGOFSXBp+vhAndTlEREQ6YaTpBu3atSszWqrUf//7X8jlcq0URbrhaGWKtwa2xH/+vI41B25gUBsn2FoYS10WERGRVml85iYuLg737t1TvT937hzmzZuHrVu3QqFQaLU40r5Jfm7wdLJEWk4B1uy/IXU5REREWqdxuBk3bhyOHj0KAEhMTMTAgQNx7tw5vP3221i5cqXWCyTtMpLL8P5IbwDAzxficDHmkcQVERERaZfG4SY8PBxdunQBAPzyyy/w9vZGSEiIajg41X0+brZ42bcJgJKbiwuLiiWuiIiISHs0DjcFBQUwMTEBUDIU/IUXXgAAeHp6IiEhQbvVkc4sHtwaDc0ViEjIwLYzMVKXQ0REpDUah5s2bdrgq6++wokTJxAUFISAgAAAQHx8POzs7LReIOmGrYUxFg3yBAB8cugWkjJyJa6IiIhIOzQON2vWrMHXX3+Nvn37YuzYsWjfvj0AYPfu3arLVVQ/jOnsgvYuDZGVV4hVeyOkLoeIiEgrNB4K3rdvXyQnJyMjIwM2Njaq5a+99hrMzc21Whzplkwm4P0R3njhi5PYfTkeYzq7oHvzRlKXRURE9Ew0PnMDAHK5HIWFhTh58iROnTqFhw8fwt3dHQ4ODtquj3TMu7E1JnRzAwC8+0c48gt5czEREdVvGoeb7OxsTJ06FUqlEr1790avXr3g7OyMadOmIScnRxc1ko7N92+FRg1MEPkwGxtOROJ0ZAr+uHQfpyNTUMTHNBARUT2jcbiZP38+jh07hj179iAtLQ1paWn4448/cOzYMSxYsEAXNZKOWZspsHRoyc3FHx+8hbHfnMHcny5h7Ddn0HPNERwI5yg4IiKqPzQON7/99hs2btyIwYMHw8rKClZWVhgyZAi++eYb/Prrr7qokWqBqVHFj85ITM/FzO2hDDhERFRvaBxucnJyKnz6t4ODAy9L1VNFxSJW/nm9wnWlF6VW7LnOS1RERFQvaBxu/Pz8sGzZMuTm/jMvyuPHj7FixQr4+flptTiqHeeiUpGQXvk8NyKAhPRcnItKrb2iiIiIakjjoeD/+9//EBAQgCZNmqB9+/YQBAGXLl2CiYkJDh06pIsaSceSMtWbwE/ddkRERFLSONx4e3vj9u3b2L59O27cuAFRFDFmzBi88sorMDMz00WNpGMOlqZabUdERCQljcMNAJiZmeHVV18tsywyMhKvvvoqjhw5opXCqPZ08bCF0toUiem5qOiuGgGAk7UpunjY1nZpREREGqvRJH4VycrKwrFjx7S1O6pFcpmAZcO8AJQEmYosG+YFuayytURERHWH1sIN1W8B3koEju8EJ+vyl55m9WuGAG+lBFURERFprkaXpUg/BXgrMdDLCeeiUpGUmYug6w/w55UEnL3LUVJERFR/MNxQGXKZAL9mdgAAv6Z2OHTtAS7EPMK5qFTec0NERPWC2uGmY8eOEITK77ngBH76x8HKFKN8m+CHs7H48ugddPHoInVJRERE1VI73IwYMUKHZVBdNaN3M/x0LhbHbj1E+P10eDe2lrokIiKiKqkdbpYtW6bLOqiOcrUzx7D2zvjjUjwCgyPx5SudpC6JiIioShwtRdWa2bcZAGBfeALuPsySuBoiIqKqMdxQtTydrPBcaweIIvDVsUipyyEiIqoSww2pZWbf5gCA38PuIz7tscTVEBERVU7ycLN+/Xp4eHjA1NQUPj4+OHHiRKVtg4ODIQhCudeNGzdqsWLD5ONmg25NbVFQJOKbE3elLoeIiKhSGoebqKgorX34zz//jHnz5mHp0qUICwtDr169MHjwYMTGxla53c2bN5GQkKB6tWjRQms1UeVm/X325qdzcUjNzpe4GiIiooppHG6aN2+Ofv36Yfv27cjNzX2mD1+7di2mTZuG6dOno3Xr1li3bh1cXFwQGBhY5XYODg5wcnJSveRy+TPVQerp1aIR2ja2xuOCImw5pb2QS0REpE0ah5vLly+jY8eOWLBgAZycnPD666/j3LlzGn9wfn4+Ll68CH9//zLL/f39ERISUuW2HTt2hFKpxIABA3D06FGNP5tqRhAEzPp75NSWkGhk5hZIXBEREVF5Gj9+wdvbG2vXrsVHH32EPXv2YMuWLejZsydatGiBadOmYcKECbC3t692P8nJySgqKoKjo2OZ5Y6OjkhMTKxwG6VSiQ0bNsDHxwd5eXnYtm0bBgwYgODgYPTu3bvCbfLy8pCXl6d6n5GRAQAoKChAQYFh/HIu7ac2+tu/pR2aNrLA3eRsbDsdhVd7ejzzPnVFm/2ubwy174bab4B9f/K/hsLQ+q1JPwVRFMVn+bC8vDysX78eS5YsQX5+PhQKBUaPHo01a9ZAqaz8SdLx8fFo3LgxQkJC4Ofnp1r+/vvvY9u2bWrfJDxs2DAIgoDdu3dXuH758uVYsWJFueU//PADzM3N1foMKutskoAfIuWwUoh4r1MRFJLflk5ERPouJycH48aNQ3p6OqysrKpsW+MHZ164cAGbNm3CTz/9BAsLCyxcuBDTpk1DfHw83nvvPQwfPrzKy1WNGjWCXC4vd5YmKSmp3NmcqnTr1g3bt2+vdP2SJUswf/581fuMjAy4uLjA39+/2h+OvigoKEBQUBAGDhwIhULxzPsbWFSM4E9PIj49F9kObTGui4sWqtQ+bfe7PjHUvhtqvwH23RD7bmj9Lr3yog6Nw83atWuxefNm3Lx5E0OGDMHWrVsxZMgQyGQl//vu4eGBr7/+Gp6enlXux9jYGD4+PggKCsLIkSNVy4OCgjB8+HC16wkLC6vyDJGJiQlMTEzKLVcoFAbxZXiStvqsUACv9W6K5Xuu49tT0XilmzuM5HX39I0hHutShtp3Q+03wL4bYt8Npd+a9FHjcBMYGIipU6diypQpcHJyqrCNq6srNm7cWO2+5s+fjwkTJsDX1xd+fn7YsGEDYmNjMWPGDAAlZ13u37+PrVu3AgDWrVsHd3d3tGnTBvn5+di+fTt+++03/Pbbb5p2g57R6M6u+PzIHcSlPsafVxIwomNjqUsiIiICUINwc/v27WrbGBsbY9KkSdW2Gz16NFJSUrBy5UokJCTA29sb+/btg5ubGwAgISGhzJw3+fn5WLhwIe7fvw8zMzO0adMGe/fuxZAhQzTtBj0jM2M5pvb0wH8P3sT64Dt4ob0zZDJB6rKIiIhqds/No0ePsHHjRkREREAQBHh6emLq1KmwtbXVeF+zZs3CrFmzKly3ZcuWMu8XLVqERYsW1aRk0oHx3dwQGByJWw+y8NeNJAz0Uv9eKSIiIl3R+EaJY8eOwd3dHZ999hkePXqE1NRUfP755/Dw8MCxY8d0USPVUdZmCkzwKznL9uXRO3jGgXdERERaoXG4mT17NkaPHo2oqCjs3LkTO3fuxN27dzFmzBjMnj1bFzVSHTa1hwdMjGS4FJeG03dTpC6HiIhI83ATGRmJBQsWlHnkgVwux/z58xEZGanV4qjus7c0wejOJUPBA4N5/ImISHoah5tOnTohIiKi3PKIiAh06NBBGzVRPfNqr6aQywScuJ2MK/fSpC6HiIgMnMY3FL/55puYO3cu7ty5g27dugEAzpw5gy+//BKrV6/GlStXVG3btWunvUqpznKxNcfwDs7YGXof649G4qsJPlKXREREBkzjcDN27FgAqHDU0tixYyEIAkRRhCAIKCoqevYKqV6Y2acZdobex4FribiTlInmDpZSl0RERAZK43ATFRWlizqonmvhaIlBbRxx8NoDBAbfxScvt5e6JCIiMlAah5vSCfaInjarb3McvPYAf1y6j7cGtkATGz6YlIiIal+NHggUGRmJOXPm4LnnnsPAgQPx5ptvcqQUob1LQ/Rs3giFxSK+OX5X6nKIiMhAaRxuDh48CC8vL5w7dw7t2rWDt7c3zp49izZt2iAoKEgXNVI9MqtvMwDAT+fjkJyVJ3E1RERkiDS+LLV48WK89dZbWL16dbnl//73vzFw4ECtFUf1j18zO7R3aYjLcWnYdDIKiwKqfjo8ERGRtml85iYiIgLTpk0rt3zq1Km4fv26Voqi+ksQBMz+++zNttMxyMgtkLgiIiIyNBqHG3t7e1y6dKnc8kuXLsHBwUEbNVE991xrR7RwaIDMvEJsOx0jdTlERGRgNL4s9eqrr+K1117D3bt30b17dwiCgJMnT2LNmjVYsGCBLmqkekYmEzCrXzO89fNlbDoZhak9PGBmLK9+QyIiIi3QONy8++67sLS0xCeffIIlS5YAAJydnbF8+XK8+eabWi+Q6qdh7ZzxyaFbuPfoMX65EIdJ3d2lLomIiAyERpelCgsLsXXrVowdOxb37t1Deno60tPTce/ePcydOxeCIOiqTqpnjOQyvN6n5N6bDcfvoqCoWOKKiIjIUGgUboyMjDBz5kzk5ZUM8bW0tISlJafZp4r9y6cJGjUwwf20x/jjUrzU5RARkYHQ+Ibirl27IiwsTBe1kJ4xVcgxvZcHAOCrY5EoLhYlroiIiAyBxvfczJo1CwsWLMC9e/fg4+MDCwuLMuv5JHB60itdXbH+6B3cScrCoesPEODtJHVJRESk5zQON6NHjwaAMjcP80ngVBlLUwUmdXfH50fuYH3wHQxq48h7s4iISKf4VHDSucnd3fHNibu4ci8dp+6koGeLRlKXREREekzje25iYmLQuHFjuLm5lXk1btwYMTGcsI3Ks2tggrFdXAEAXx69I3E1RESk7zQON/369UNqamq55enp6ejXr59WiiL982qvplDIBZy+m4LQ2EdSl0NERHpM43BTem/N01JSUsrdXExUyrmhGUZ0aAwAWH80UuJqiIhIn6l9z82LL74IoOTm4cmTJ8PExES1rqioCFeuXEH37t21XyHpjRl9m+HX0Hs4HPEAv5yPg4lCBgdLU3TxsIVcxpuMiYhIO9QON9bW1gBKztxYWlrCzMxMtc7Y2BjdunXDq6++qv0KSW80s2+Aji4NERqbhkW/XVEtV1qbYtkwLwR4KyWsjoiI9IXa4Wbz5s0AAHd3dyxcuJCXoEhjB8ITEBqbVm55YnouZm4PReD4TloLOEXFIs5GpeJisgC7qFT4NXfg2SEiIgOh8VDwZcuW6aIO0nNFxSJW7Lle4ToRgABgxZ7rGOjl9Mwh5EB4AlbsuY6E9FwAcmy9fYFnh4iIDIjG4ebBgwdYuHAh/vrrLyQlJUEUy06pz0n8qCLnolL/DhsVEwEkpOdixJcn0dS+AWzMjWFr8c+r9L2NhQI25sZQyCu+F/5AeAJmbg/F0w960MXZISIiqps0DjeTJ09GbGws3n33XSiVSs42S2pJyqw82Dzp6v0MXL2fUW07K1Ojv8OOMWz/Dj4NzRX46XxcuWADaP/sEBER1V0ah5uTJ0/ixIkT6NChgw7KIX3lYGmqVruZfZrB1sIYqTn5eJSdj9TS19/v0x4XQBSBjNxCZOQWIjolR+0aSs8OnYtKhV8zuxr2hIiI6jqNw42Li0u5S1FE1eniYQultSkS03MrPLMiAHCyNsXCQa2qPKtSVCwi/XEBUrPzkJpdgNTsfDzKKQlA56NTEXzzYbW1qHsWiYiI6ieNw826deuwePFifP3113B3d9dBSaSP5DIBy4Z5Yeb2UAhAmYBTGmWWDfOq9nKRXCao7sN52unIFLXCjbpnkYiIqH6q0VPBc3Jy0KxZM5ibm0OhUJRZX9GjGYgAIMBbicDxnZ4YyVTCSUsjmdQ9O9TFw/aZPoeIiOq2Gp25IaqpAG8lBno54VxUKpIyc7U6Q3FVZ4fw93t1zg4REVH9pnG4mTRpki7qIAMilwk6u6G3srNDAGDfwBj9PR118rlERFR3qP3gzF9++QX5+fmq99HR0WXmtMnJycFHH32k3eqIaiDAW4mT/+6P7VN9MbFFEb4Z3xF2FsZ4mJWP78/GSF0eERHpmNrhZuzYsUhLS1O9b9euHWJi/vlFkZmZiSVLlmi1OKKakssEdPWwhU8jEX1b2WO+f0sAwGd/3Ub64wKJqyMiIl1SO9w8Pfybw8GpPhnt64LmDg3wKKcAgcGRUpdDREQ6pHa4IarPjOQyLA7wBABsOhWF+2mPJa6IiIh0heGGDMaA1g7o6mGL/MJifHLoptTlEBGRjmg0WurgwYOwtrYGABQXF+Ovv/5CeHg4AJS5H4eoLhIEAW8PaY3hX57C72H3Ma2nB9o4W0tdFhERaZlG4ebpYeCvv/56mfd8iCbVde1dGmJYe2fsuRyPD/fdwLZpXfi9JSLSM2pfliouLq729eTQcKK6atGgVjCWy3DyTjKO306WuhwiItIy3nNDBsfF1hwT/dwAAB/ui0BRMUf+ERHpE4YbMkhv9G8OK1Mj3EjMxG+h96Quh4iItIjhhgxSQ3NjvNG/OQDgk0M38Tifl1SJiPQFww0ZrIl+7mjc0AwPMvKw6VSU1OUQEZGWMNyQwTJVyLEooBUAIDA4EslZeRJXRERE2qBxuImLi8O9e//co3Du3DnMmzcPGzZs0GphRLVhWDtntG1sjay8Qnz2122pyyEiIi3QONyMGzcOR48eBQAkJiZi4MCBOHfuHN5++22sXLlS6wUS6ZJMJmDJkJLHMvxwNhZ3H2ZJXBERET0rjcNNeHg4unTpAgD45Zdf4O3tjZCQEPzwww/YsmWLtusj0rnuzRqhv6cDCotFfHSAj2UgIqrvNA43BQUFMDExAQAcPnwYL7zwAgDA09MTCQkJ2q2OqJYsGewJmQAcuJaIC9GpUpdDRETPQONw06ZNG3z11Vc4ceIEgoKCEBAQAACIj4+HnZ2d1gskqg0tHC0xurMLAOCDfREQRU7sR0RUX2kcbtasWYOvv/4affv2xdixY9G+fXsAwO7du1WXq4jqo7eeawkzhRyhsWnYH54odTlERFRDGj04EwD69u2L5ORkZGRkwMbGRrX8tddeg7m5uVaLI6pNDlameLV3U3z21218dOAGnmvtCGMjzpZARFTfaPwv9+PHj5GXl6cKNjExMVi3bh1u3rwJBwcHrRdIVJte790UjRqYIDolBz+cjZG6HCIiqgGNw83w4cOxdetWAEBaWhq6du2KTz75BCNGjEBgYKDWCySqTRYmRnhrYAsAwP/+uo2M3AKJKyIiIk1pHG5CQ0PRq1cvAMCvv/4KR0dHxMTEYOvWrfjss880LmD9+vXw8PCAqakpfHx8cOLECbW2O3XqFIyMjNChQweNP5OoKqN9XdDM3gKPcgoQGBwpdTlERKQhjcNNTk4OLC0tAQCHDh3Ciy++CJlMhm7duiEmRrPT+D///DPmzZuHpUuXIiwsDL169cLgwYMRGxtb5Xbp6emYOHEiBgwYoGn5RNUyksuweHBrAMCmk1GIT3sscUVERKQJjcNN8+bNsWvXLsTFxeHgwYPw9/cHACQlJcHKykqjfa1duxbTpk3D9OnT0bp1a6xbtw4uLi7VXt56/fXXMW7cOPj5+WlaPpFanmvtgC4etsgrLMYnh25JXQ4REWlA43Dz3nvvYeHChXB3d0eXLl1UAePQoUPo2LGj2vvJz8/HxYsXVeGolL+/P0JCQirdbvPmzYiMjMSyZcs0LZ1IbYIgYOmQkrM3O8Pu4Xp8hsQVERGRujQeCj5q1Cj07NkTCQkJqjluAGDAgAEYOXKk2vtJTk5GUVERHB0dyyx3dHREYmLFc4zcvn0bixcvxokTJ2BkpF7peXl5yMv752nPGRklv6QKCgpQUGAYN4uW9tNQ+lvqWfvt5WSBoW2dsPdqIt7fex1bJvtoszyd4jE3rH4D7PuT/zUUhtZvTfqpcbgBACcnJzg5OeHevXsQBAGNGzeu8QR+giCUeS+KYrllAFBUVIRx48ZhxYoVaNmypdr7//DDD7FixYpyyw8dOmRw8/IEBQVJXYIknqXfPkbAAUGOU5EpWPvDfng2rF8zF/OYGx723fAYSr9zcnLUbiuIGs4zX1xcjFWrVuGTTz5BVlbJE5QtLS2xYMECLF26FDKZele68vPzYW5ujh07dpQ54zN37lxcunQJx44dK9M+LS0NNjY2kMvlZWoRRRFyuRyHDh1C//79y31ORWduXFxckJycrPE9QvVVQUEBgoKCMHDgQCgUCqnLqTXa6vcH+29ic0gMPB0bYNcsP8hl5cN3XcNjblj9Bth3Q+y7ofU7IyMDjRo1Qnp6erW/vzU+c7N06VJs3LgRq1evRo8ePSCKIk6dOoXly5cjNzcX77//vlr7MTY2ho+PD4KCgsqEm6CgIAwfPrxceysrK1y9erXMsvXr1+PIkSP49ddf4eHhUeHnmJiYqB70+SSFQmEQX4YnGWKfgWfv99znWuK30Pu48SALe64+wL98XbRYnW7xmBse9t3w+m4o/dakjxqHm++++w7ffvut6mngANC+fXs0btwYs2bNUjvcAMD8+fMxYcIE+Pr6ws/PDxs2bEBsbCxmzJgBAFiyZAnu37+PrVu3QiaTwdvbu8z2Dg4OMDU1LbecSJsamhvjjf7N8cG+G/jk0C08384ZZsby6jckIiJJaBxuUlNT4enpWW65p6cnUlNTNdrX6NGjkZKSgpUrVyIhIQHe3t7Yt28f3NzcAAAJCQnVznlDVBsm+rnju5AY3E97jE2nojC7X3OpSyIiokpoPBS8ffv2+OKLL8ot/+KLL8qMnlLXrFmzEB0djby8PFy8eBG9e/dWrduyZQuCg4Mr3Xb58uW4dOmSxp9JpClThRz/N6gVACAwOBIpWXnVbEFERFLR+MzNRx99hKFDh+Lw4cPw8/ODIAgICQlBXFwc9u3bp4saieqEF9o749uTdxF+PwOf/XUbK4bzcigRUV2k8ZmbPn364NatWxg5ciTS0tKQmpqKF198ETdv3lQ9c4pIH8lkAt7+e2K/78/G4u7DLIkrIiKiimh05qagoAD+/v74+uuvNbpxmEhfdG/WCP09HXDkRhLW7L+ByT08kJSZCwdLU3TxsK0Xw8SJiPSdRuFGoVAgPDy8wkn2iAzF4sGeOHojCQevP8DB6w9Uy5XWplg2zAsB3koJqyMiIo0vS02cOBEbN27URS1E9cLdh1moaObLxPRczNweigPhCbVeExER/UPjG4rz8/Px7bffIigoCL6+vrCwsCizfu3atVorjqiuKSoWsWLP9QrXiQAEACv2XMdALydeoiIikojG4SY8PBydOnUCANy6davMOl6uIn13LioVCem5la4XASSk5+JcVCr8mtnVXmFERKSicbg5evSoLuogqheSMisPNjVpR0RE2qf2PTdFRUW4cuUKHj9+XG5dTk4Orly5guLiYq0WR1TXOFiaarUdERFpn9rhZtu2bZg6dSqMjY3LrTMxMcHUqVPxww8/aLU4orqmi4ctlNamqOoCrNK6ZFg4ERFJQ+1ws3HjRixcuBByefkHBsrlcixatAgbNmzQanFEdY1cJmDZMC8AqDTgvNipMW8mJiKSkNrh5ubNm+jWrVul6zt37oyIiAitFEVUlwV4KxE4vhOcrMteejJTlAT/TSejceVemgSVERERoMENxdnZ2cjIyKh0fWZmJnJycrRSFFFdF+CtxEAvJ5yLSlXNUNzRtSFe3XoBJ24nY+qW8/h9Vg+42JpLXSoRkcFR+8xNixYtEBISUun6kydPokWLFlopiqg+kMsE+DWzw/AOjeHXzA6mCjnWv9IJrZVWSM7Kx6TN5/AoO1/qMomIDI7a4WbcuHF45513cOXKlXLrLl++jPfeew/jxo3TanFE9Y2lqQJbpnSGs7Up7j7MxqtbLyC3oEjqsoiIDIral6Xeeust7N+/Hz4+Pnjuuefg6ekJQRAQERGBw4cPo0ePHnjrrbd0WStRveBoZYotU7vgpcAQXIh5hAW/XMbnYztCxpuMiYhqhdpnbhQKBQ4dOoT3338fCQkJ2LBhA7766iskJCTg/fffx6FDh6BQKHRZK1G90dLREl9P8IFCLmDv1QR8sI832xMR1RaNnwq+aNEiLFq0SFf1EOmN7s0a4eN/tcfcny7h25NRaGxjhik9PKQui4hI72n8VHAiUt/wDo2xKKAVAGDln9f5xHAiolrAcEOkYzP7NMP4bq4QRWDuT5dwMSZV6pKIiPQaww2RjgmCgOXD2mCApwPyCosx/bsLuPswS+qyiIj0FsMNUS0wksvw+biOaN/EGo9yCjB583kkZ+VJXRYRkV7SONwEBwfroAwi/WdubIRvJ3WGi60ZYlNzMO27C8jJL5S6LCIivaNxuAkICECzZs2watUqxMXF6aImIr1lb2mCLVO6oKG5Apfj0vDmj5dQVCxKXRYRkV7RONzEx8dj7ty52LlzJzw8PDBo0CD88ssvyM/nNPNE6mhm3wDfTvSFsZEMhyMeYPnuaxBFBhwiIm3RONzY2trizTffRGhoKC5cuIBWrVph9uzZUCqVePPNN3H58mVd1EmkV3zdbfG/0R0gCMC2MzH4+vhdqUsiItIbz3RDcYcOHbB48WLMnj0b2dnZ2LRpE3x8fNCrVy9cu3ZNWzUS6aXBbZV4Z6gXAGD1/hv449J9iSsiItIPNQo3BQUF+PXXXzFkyBC4ubnh4MGD+OKLL/DgwQNERUXBxcUF//rXv7RdK5HemdbTA1P/nrX4/3ZcwZm7KRJXRERU/2kcbubMmQOlUokZM2agZcuWCAsLw+nTpzF9+nRYWFjAxcUFq1evxo0bN3RRL5HeeWdoawz2dkJ+UTFe23oBtx9kSl0SEVG9pnG4uX79Oj7//HPEx8dj3bp18Pb2LtfG2dkZR48e1UqBRPpOJhPw6egO8HGzQUZuISZvPo8HGblSl0VEVG9pFG4KCgrg6uqKrl27wtjYuNJ2RkZG6NOnzzMXR2QoTBVyfDvRF00bWeB+2mNM2XweWXmcA4eIqCY0CjcKhQK///67rmohMmg2FsbYMqULGjUwxvWEDMz6PhS5BUU4HZmCPy7dx+nIFM6JQ0SkBiNNNxg5ciR27dqF+fPn66IeIoPmameOjZM6Y8yGMzh+6yE6rgzC44Ii1XqltSmWDfNCgLdSwiqJiOo2jcNN8+bN8Z///AchISHw8fGBhYVFmfVvvvmm1oojMkTtXRpiSg93rA+OLBNsACAxPRczt4cicHwnBhwiokpoHG6+/fZbNGzYEBcvXsTFixfLrBMEgeGG6BkVFYv4PaziOW9EAAKAFXuuY6CXE+QyoVZrIyKqDzQON1FRUbqog4j+di4qFQnplY+WEgEkpOfiXFQq/JrZ1V5hRET1xDPNUExE2peUqd4wcHXbEREZGo3P3ADAvXv3sHv3bsTGxpZ7YObatWu1UhiRoXKwNFWr3eW4NAxpq4RCzv9HISJ6ksbh5q+//sILL7wADw8P3Lx5E97e3oiOjoYoiujUqZMuaiQyKF08bKG0NkViei6qGvi96VQ0jt58iP8b1AqDvZ0gCLz/hogIqMFlqSVLlmDBggUIDw+HqakpfvvtN8TFxaFPnz58nhSRFshlApYNK3mg5tNxRfj7NaazC+wsjBGVnI1Z34dixPoQnI7kc6mIiIAahJuIiAhMmjQJQMlMxI8fP0aDBg2wcuVKrFmzRusFEhmiAG8lAsd3gpN12UtUTtamCBzfCatfaodji/ph7oAWMDeW43JcGsZ+cwaTN59DREKGRFUTEdUNGl+WsrCwQF5eHoCSZ0hFRkaiTZs2AIDk5GTtVkdkwAK8lRjo5YRzUalIysyFg6UpunjYqoZ/NzAxwlsDW2J8Nzd8fuQ2fjgbi+CbD3Hs1kMMb6dEe7nEHSAikojG4aZbt244deoUvLy8MHToUCxYsABXr17Fzp070a1bN13USGSw5DKh2uHe9pYmWDncG1N7eOC/h25i75UE7LqcgD2CHHGmNzFnQEvYWFT+LDgiIn2j8WWptWvXomvXrgCA5cuXY+DAgfj555/h5uaGjRs3ar1AIlKPeyMLfDmuE/6Y3QPdPGxQJArYFBKD3h8dxZdH7+BxflH1OyEi0gMan7lp2rSp6s/m5uZYv369VgsiomfT3qUhtk7xxdofDyD4UUPcSMzEfw/exNbT0XjruZYY5dMERk8MHy8qFiu99EVEVB/VaJ4bAMjPz0dSUhKKi4vLLHd1dX3moojo2QiCgNYNRbw1phv2XU/Cxwdv4X7aYyzeeRXfnozCokGtMNDLEQevJWLFnutlZkTmwzmJqL7TONzcunUL06ZNQ0hISJnloihCEAQUFfHUN1FdIZMJGNmxCYa0VWLb6Rh8cfQO7iRl4bVtF9HU3gJ3H2aX24YP5ySi+k7jcDNlyhQYGRnhzz//hFKp5MRhRPWAiZEc03s1xcudXfD1sUh8e+JuhcEG4MM5iaj+0zjcXLp0CRcvXoSnp6cu6iEiHbIyVeD/BnmijbM1Zn0fWmk7PpyTiOozjUdLeXl5cT4bonquoKi4+kbgwzmJqH7SONysWbMGixYtQnBwMFJSUpCRkVHmRUR1n7oP57z1IBP5heoFISKiukLjy1LPPfccAGDAgAFllvOGYqL6Q92Hc355NBK/XbyPSd3dMa6LK6zNFbVWIxFRTWkcbo4ePaqLOoioFpU+nHPm9lAIQJmAU3r78LD2Spy+m4rEjFysOXADn/11Gy/7NsGUHh5wb2QhQdVEROrRONz06dNHF3UQUS0rfTjn0/PcOD0xz01eYRH2XE7Atyfu4kZiJr47HYOtZ2IwsLUjpvdqis7uNhwxSUR1jlrh5sqVK/D29oZMJsOVK1eqbNuuXTutFEZEulfdwzlNjOQY5dMEL3VqjJDIFHx74i6O3nyIQ9cf4ND1B2jXxBrTenpgSFslFHKNb+EjItIJtcJNhw4dkJiYCAcHB3To0AGCIEAUy1+p5z03RPWPOg/nFAQBPZo3Qo/mjXAnKRMbT0ZjZ+g9XLmXjrk/XcLq/Tcwubs7xnRxhbUZ78shImmpFW6ioqJgb2+v+jMRGa7mDpb48MW2WOjfEtvPxGLbmWgkpOfiw/1/35fT2QVTunvA1c5ctQ2fX0VEtUmtcOPm5lbhn4nIcNk1MMHc51rg9T5NsftSPL49eRe3HmRh86lofBcSjUFtnDC9lweSMvKw8k8+v4qIao/GF8lTUlJUf46Li8N7772H//u//8OJEydqVMD69evh4eEBU1NT+Pj4VLmfkydPokePHrCzs4OZmRk8PT3x6aef1uhziUg7TBVyvNzZBQfn9cbWqV3Qu6U9ikVgf3giXgo8jZnfh5YJNsA/z686EJ4gUdVEpM/UDjdXr16Fu7s7HBwc4OnpiUuXLqFz58749NNPsWHDBvTr1w+7du3S6MN//vlnzJs3D0uXLkVYWBh69eqFwYMHIzY2tsL2FhYWeOONN3D8+HFERETgnXfewTvvvIMNGzZo9LlEpH2CIKB3S3tsndoFB+f1xr98mlTatvSOvRV7rqOouKqZdoiINKd2uFm0aBHatm2LY8eOoW/fvnj++ecxZMgQpKen49GjR3j99dexevVqjT587dq1mDZtGqZPn47WrVtj3bp1cHFxQWBgYIXtO3bsiLFjx6JNmzZwd3fH+PHjMWjQoBqfNSIi3WjlZIkXO1UeboB/nl+1+9L9CgcoEBHVlNrh5vz583j//ffRs2dPfPzxx4iPj8esWbMgk8kgk8kwZ84c3LhxQ+0Pzs/Px8WLF+Hv719mub+/P0JCQtTaR1hYGEJCQjj3DlEdpO5zqd765TK6rz6C+T9fwi/n4xCXmqPjyohI36k9iV9qaiqcnJwAAA0aNICFhQVsbW1V621sbJCZman2BycnJ6OoqAiOjo5lljs6OiIxMbHKbZs0aYKHDx+isLAQy5cvx/Tp0yttm5eXh7y8PNX70udfFRQUoKCgQO1667PSfhpKf0sZar+ButF3O3P1/nmRy0rO4OwMu4+dYfcBAI0bmqKrhy26ediiW9OSR0VUp6hYxJnIh7iYLMD6dhK6NbM3qBFZdeGYS8VQ+25o/daknxrNUPz0TKTamJn06X2UPqOqKidOnEBWVhbOnDmDxYsXo3nz5hg7dmyFbT/88EOsWLGi3PJDhw7B3Ny8gi30V1BQkNQlSMJQ+w1I2/diEWhoLEdaPvDPQx2eJKKhMbCkfRFisgXcSRdwO0NATBZwPy0XO8PisTMsHgDQyEREc2sRLaxEtLAWYW1cdk+XUwTsjJYhLV8AIMfW25fQ0FjEi+7FaG9nWJe8+H03PIbS75wc9c/qahRuJk+eDBMTEwBAbm4uZsyYAQuLkmfMPHl2RB2NGjWCXC4vd5YmKSmp3Nmcp3l4eAAA2rZtiwcPHmD58uWVhpslS5Zg/vz5qvcZGRlwcXGBv78/rKysNKq5viooKEBQUBAGDhwIhcJwJlgz1H4DdafvCvcHmPPTZQAVPb9KwKoX22NQm7J/37PzChEam4YzUak4E5WKa/GZSM4DkpMEnEkqaeNhZ46uTW3R1d0GuQVF2Hz6erkHgKbnC9h8S47Px5T/DH1UV465FAy174bW79IrL+pQO9xMmjSpzPvx48eXazNx4kS1P9jY2Bg+Pj4ICgrCyJEjVcuDgoIwfPhwtfcjimKVwcrExEQVyJ6kUCgM4svwJEPsM2C4/Qak7/vzHZrAyEhe5fOrntZQoUB/LzP09ypZl5lbgAvRj3D6bgpOR6bgWnw6olJyEJWSg5/O36v0s0WUhKj399/E4HaNDeYSldTHXEqG2ndD6bcmfVQ73GzevLlGxVRl/vz5mDBhAnx9feHn54cNGzYgNjYWM2bMAFBy1uX+/fvYunUrAODLL7+Eq6srPD09AZTMe/Pxxx9jzpw5Wq+NiLSjuudXVcfSVIF+ng7o5+kAAEh/XIBzUak4HZmCwxEPEFvFDcilI7LORaVW+4gJItIfGj8VXJtGjx6NlJQUrFy5EgkJCfD29sa+fftUsyAnJCSUmfOmuLgYS5YsQVRUFIyMjNCsWTOsXr0ar7/+ulRdICI1qPP8KnVZmykw0MsRA70c0d7FGnN/ulTtNttOR8OugTFaODTgU8yJDICk4QYAZs2ahVmzZlW4bsuWLWXez5kzh2dpiEjFwbL6UVQAsC88EfvCE9G0kQUGeTthUBsntG9izaBDpKckDzdERDXVxaNkmHhiem65G4qBknturMwU8HFtiJN3UnA3ORuBwZEIDI6E0toUg9qUBJ3O7jYwkmv8NBoiqqMYboio3pLLBCwb5oWZ20MhoKIRWcCal9oiwFuJzNwCBN98iAPXEhF8IwkJ6bnYEhKNLSHRsLUwxnOtHRDg7YQezRvBxEhe4efx6eZE9QPDDRHVawHeSgSO71TtiCxLUwWGtXfGsPbOyC0owqk7yTgQnoigiAdIzc7HLxfu4ZcL99DAxAj9PB0Q0MYJfVvZw8Kk5J/JA+EJ5T6DTzcnqpsYboio3isdkXX6ThIOnTgL/15d4dfcodKzKqYKOQa0dsSA1o4oLCrGuahUHLiWiIPXEvEgIw97Lsdjz+V4GBvJ0LtFIzg3NMO20zHlLn2VPt08cHwnBhyiOoThhoj0glwmoKuHLVIiRHTV4HKRkVyG7s0boXvzRlg+rA0u30srCTrhiYhOycHhiKRKty2dS2fFnusY6OXES1REdQTDDRHR32QyAR1dbdDR1QaLAzxx80Emvj0ehV9Dq54skHPpENUtHB5ARFQBQRDg6WSFXi0bqdVe3aegE5HuMdwQEVVB3bl07CyMq29ERLWC4YaIqAqlc+lUdzfNx4duIio5u1Zqon8UFYs4G5WKi8kCzkaloqjYsJ4CTxVjuCEiqkLpXDoAygWc0vemChkuxaVjyP9OYNuZGIgif8HWhgPhCei55gjGb7qArbflGL/pAnquOYID4QlSl0YSY7ghIqpG6Vw6TtZlL1E5WZviq/GdcGRBX3RvZofHBUV4d1c4Jm8+jwcZvAdHlw6EJ2Dm9tAy8w4B/wzPZ8AxbBwtRUSkhuqebr59WldsCYnGmgM3cOzWQwxadxyrRnjj+XbOEleuf4qKRazYc73CR25weD4BPHNDRKS20qebD+/QGH7N7Mr84pTJBEzt6YE/5/SEd2MrpOUU4I0fwjD3pzCk5xRIWLX+OReVWu6MzZOeHJ5PhonhhohIi1o4WmLnzB6Y0785ZALwx6V4DFp3HCdvJ0tdmt5Qd9g9h+cbLoYbIiItMzaSYYF/K/w6szvc7cyRmJGL8RvPYvnua3icXyR1efWeusPz1W1H+ofhhohIRzq52mDf3F4Y380VALAlJBrPf34Cl+PSpC2snsstqD4gNjAxgo+bTS1UQ3URww0RkQ6ZGxth1Yi22DKlMxwsTRD5MBsvBoZg3eFbKCgqlrq8eufYrYd4fftF1fvKbhfOyivE5M3nkJyVVzuFUZ3CcENEVAv6tnLAwXm9MbSdEkXFItYdvo1RgSGIfJgldWn1xrFbD/Hq1gvILyyGv5cjPh/bsdzwfKW1Kab2cIe5sRwhkSkY+tkJnI/mjcWGhkPBiYhqiY2FMb4Y2xH+Xo54d1c4Lt9Lx9DPTuDtIa0xoZsbBKHkPERRsVjpkHND9XSw+WJcJxgbyTCkrRKn7yTh0Imz8O/VFX7NHSCXCRjbxRUzvw/FnaQsjNlwBksGe2JaTw/Vz5j0G8MNEVEtEgQBwzs0RhcPW/zfjis4eScZ7/1xDUHXH+C/o9rjUtwjrNhzvcxQZ6W1KZYN80KAt1LCyqVTWbABSobnd/WwRUqEiK5PhMAWjpb4Y3YPLN55FXsux2PV3ghcjHmEj0a1g6WpQsruUC3gZSkiIgkorc2wdWoXLB/mBRMjGU7cTkb/T4Ixg7PullFVsKmOhYkRPhvTASuHt4FCLmB/eCJe+OIUIhIydFw1SY3hhohIIjKZgMk9PLD3zV7wdrZCTiXDxEtn4l2x57pBPRjyWYJNKUEQMNHPHb+87gdna1NEJWdj5PpT+PXiPR1VTXUBww0RkcSaOzTA4sGeVbYxtFl3tRFsntTR1QZ73+yFPi3tkVtQjIU7LmPxb1fUGlZO9Q/DDRFRHZCSna9WO0OYdVfbwaaUjYUxNk/ujPkDW0IQgJ/Ox+GlwBDEpuRooWqqSxhuiIjqAHVn0113+DYCgyP19heyroJNKZlMwJsDWmDr1C6wtTDGtfgMDP38BIKuP9DaZ5D0GG6IiOqALh62UFqbVjopXamo5GysOXADvf97FM9/fgLrg+8gJiW7VmrUNV0Hmyf1amGPP+f0RCfXhsjMLcSrWy9g9f4bKOTEinqB4YaIqA6QywQsG+YFoPysu8Lfr49GtcP7I73Ro7kdZAIQfj8DHx24iT7/DcaIwNMIui8gJrV+ntGpzWBTyrmhGX56zQ9TergDAL46FolXvj1rEJf+9B3nuSEiqiMCvJUIHN+p3Dw3Tk/Nc/NKVzekZOXh4LUH2Hc1ASGRybgWn4lrkOPPT0+ijbMVhrRVYmhbJdwbWVT4WXVpokApgk0pYyMZlg1rA183Wyz69TLORqVi6Gcn8cXYjuja1A5A3fpZkXoYboiI6pAAbyUGejlV+8vUroEJxnV1xbiurkjJysO+K/HYdiwckZlyXIvPwLX4DPz34M0Kg86B8IQ6M1GglMHmSUPbKeGptMTM7Rdx60EWxn17Fv83qBXcbM2x8s+68bMi9THcEBHVMXKZAL9mdmq3t2tggjGdm8Dq4RV069MfR26l/H1GJ6VM0PFSWqGFYwP8cSm+3D5KJwoMHN+p1n5p15VgU6qZfQPsmt0D7/wejp1h97F6/40K20nxsyLN8J4bIiI9YmthjLFdXLFtWlecX/ocPnyxLXq1aAS5TMD1hIwKgw1Q+xMF1rVgU8rc2AifvNwe/xnRptI2hjqpYn0i/TeJiIh04umg82ovjyrb/zNRYIpO66qrwaaUIAhobm9ZZRtDm1SxvuFlKSIiA2BrYQzvxtZqtX1920X093RA9+aN0L2ZHZrYmGutjroebEqpO2KKI6vqJoYbIiIDoe5EgRm5hdh1KR67/r6E5Wprjh7N7eDXrBH8mtrB3tJErf08Pcoot6AIr2+/WOeDDaD+z0rddlS7GG6IiAxE6USBiem5qOhOEQGAo7UpPh7VDmfupiIkMhmX76UjNjUHsedy8OO5OABAS8cG6N6s5KxO16Z2sDZTlNtXRSOyStX1YAOo97Nysi4ZyUZ1D8MNEZGBKJ0ocOb2UAhAmV/apQPNlw/zQs8W9ujZwh5AK2TlFeJ8VCpO3UlGSGQKridk4NaDLNx6kIUtIdGQCYB3Y2tV2PF1t8HxWw8xc3tohaEAAIa1d67TwQao+meFv9+/O9SL893UUQw3REQGRN2JAks1MDFCP08H9PN0AACkZufj7N0UnIosCTt3H2bjyr10XLmXjq+ORcJIBsgEodJgIwD4YF8EhrRV1vlgUNnPqtTNB5kYAg4Fr4sYboiIDIy6EwVWxNbCGIPbKjG4bckv9cT0XJy+m4xTd1IQcicZ8em5KH+e4x9PjjLSZC4fqVT0s4pJzcbi367if3/dRisnSwxpy4BT1zDcEBEZIE0nCqyMk7UpRnZsgpEdm0AURWw6FYX//BlR7Xb1aZTR0z8rv2Z2uP0gCxtPRmHBL5fhZmeONs7qjUSj2lG3L3oSEVG9IQgCvJTq/ZKv76OMlgz2RO+W9nhcUIRXv7uAh5l5UpdET2C4ISIirSkdZVTZBS4BJc9mqu+jjIzkMnw+tiOaNrJAfHouZmy/iLzCIqnLor8x3BARkdaUjjICUC7glL5fNkw/RhlZmynwzSRfWJoa4WLMI7zzezhEkY9jqAsYboiISKtKRxk5WZe99ORkbap3D5tsZt8AX4zrBJkA7Lh4D5tORUtdEoE3FBMRkQ48y4is+qZPS3u8PaQ1Vu2NwPt7r6O5QwP0aWkvdVkGjWduiIhIJ0pHGQ3v0Bh+zez0MtiUmtbTA//yaYJiEXjjh1BEPsySuiSDxnBDRET0jARBwKqR3vBxs0FmbiFe/e4C0h8XSF2WwWK4ISIi0gITIzm+Gu8DZ2tT3E3Oxpwfw1BYVCx1WQaJ4YaIiEhL7C1N8M0kX5gp5Dh+6yE+3H9D6pIMEsMNERGRFrVxtsYnL7cHAGw8GYVfzsdJXJHhYbghIiLSsiFtlZg7oAUAYOmuq7gQnSpxRYaF4YaIiEgH5g5ogcHeTigoEjFj+0XcT3ssdUkGg+GGiIhIB2QyAZ+83B6tlVZIzsrHq99dQE5+odRlGQSGGyIiIh0xNzbCNxN9YGdhjOsJGVi44zKKi/mIBl1juCEiItKhJjbm+HqCDxRyAfuuJuKzI7elLknvMdwQERHpmK+7Ld4f0RYAsO7wbey/miBxRfqN4YaIiKgWvNzZBVN7eAAA5v9yGdfi0yWuSH8x3BAREdWSt4d4oleLRnhcUITXtl5Eclae1CXpJYYbIiKiWmIkl+GLsZ3QtJEF7qc9xoxtF5FXWCR1WXpH8nCzfv16eHh4wNTUFD4+Pjhx4kSlbXfu3ImBAwfC3t4eVlZW8PPzw8GDB2uxWiIiomdjba7AN5N8YWlqhAsxj/DurnAUFhXjdGQK/rh0H6cjU1DEEVXPRNJw8/PPP2PevHlYunQpwsLC0KtXLwwePBixsbEVtj9+/DgGDhyIffv24eLFi+jXrx+GDRuGsLCwWq6ciIio5prZN8AX4zpBJgC/XLiHTv8JwthvzmDuT5cw9psz6LnmCA6E86bjmpI03KxduxbTpk3D9OnT0bp1a6xbtw4uLi4IDAyssP26deuwaNEidO7cGS1atMAHH3yAFi1aYM+ePbVcORER0bPp09IeL3ZsDADIyC07uV9iei5mbg9lwKkhycJNfn4+Ll68CH9//zLL/f39ERISotY+iouLkZmZCVtbW12USEREpDNFxSJORqZUuK70otSKPdd5iaoGjKT64OTkZBQVFcHR0bHMckdHRyQmJqq1j08++QTZ2dl4+eWXK22Tl5eHvLx/7kbPyMgAABQUFKCgoKAGldc/pf00lP6WMtR+A4bbd0PtN8C+P/nf+uJsVCoS03MrXS8CSEjPxek7SejqUf5/4utrv2tKk35KFm5KCYJQ5r0oiuWWVeTHH3/E8uXL8ccff8DBwaHSdh9++CFWrFhRbvmhQ4dgbm6uecH1WFBQkNQlSMJQ+w0Ybt8Ntd8A+16fXEwWAMirbffm9+fR0U5ES2sRTS1FGD+1SX3rd03l5OSo3VaycNOoUSPI5fJyZ2mSkpLKnc152s8//4xp06Zhx44deO6556psu2TJEsyfP1/1PiMjAy4uLvD394eVlVXNO1CPFBQUICgoCAMHDoRCoZC6nFpjqP0GDLfvhtpvgH2vj323i0rF1tsXqm2Xmifgr3gBf8UDxkYy+Lo2RPdmdujqZo174WcwyF+9fhcVi7gQ8whJmXlwsDSBr5sN5LLqTybUFaVXXtQhWbgxNjaGj48PgoKCMHLkSNXyoKAgDB8+vNLtfvzxR0ydOhU//vgjhg4dWu3nmJiYwMTEpNxyhUJRr/4SaIMh9hkw3H4Dhtt3Q+03wL7Xp777NXeA0toUiem5qOiuGgGAg5UJ/j3IE6ciU3DyzkM8yMhDyN1UhNxNBQCYG8lxKPM6erV0QM/mjeBqV/EViQPhCVix5zoSnrgMprQ2xbJhXgjwVuqgd9qnybGV9LLU/PnzMWHCBPj6+sLPzw8bNmxAbGwsZsyYAaDkrMv9+/exdetWACXBZuLEifjf//6Hbt26qc76mJmZwdraWrJ+EBERaUouE7BsmBdmbg+FAJQJOKXnU1a80AYB3kq86NMEoigi8mEWTt5Oxsk7KTh9NxnZeUXYf+0B9l97AABwtTVHj+aN0LN5I3RvZgcbC2McCE/AzO2h5QJU6YiswPGd6k3AUZek4Wb06NFISUnBypUrkZCQAG9vb+zbtw9ubm4AgISEhDJz3nz99dcoLCzE7NmzMXv2bNXySZMmYcuWLbVdPhER0TMJ8FYicHyncmdVnCo4qyIIApo7WKK5gyUm9/BATm4eNvx6AMUOrXDm7iOExj5CbGoOYs/F4sdzsRAEoI3SClEp2RWeGRJREqJW7LmOgV5O9eoSVXUkv6F41qxZmDVrVoXrng4swcHBui+IiIioFgV4KzHQywnnolKRlJkLB0tTdPGwrTZsKOQyeFgCQ/o1w3x/BbLyCnEuKgUnb5dcwrr1IAvh8VXfp1I6IutcVCr8mtlpsVfSkjzcEBERGTq5THjmcNHAxAj9PR3R37NkUE5SRi4+P3Ib285UPOv/k3Zfvg+7BsZobt8AMj04g8NwQ0REpIccrEwxpK2zWuHmx3Nx+PFcHCxNjNDepSE6ujZEJ1cbdHBpCBsLY7U/s6hY1PgMlC4w3BAREempLh62VY7IAoAGJnK0cbbC1fsZyMwrxMk7yTh5J1m13qORBTr+HXg6utqglZMlFPLyDzioSyOyGG6IiIj0lDojsj7+V3sEeCtRWFSMWw+yEBb3CGGxaQiLfYTIh9mISi557Qy7DwAwVcjQrnFp2CkJPGGxj+rUiCyGGyIiIj2m7ogsI7kMXs5W8HK2witdS0Ytp+Xk41JcWknYiUvDpdhHyMgtxLnoVJyLTlXtSyagTo3IYrghIiLSczUdkdXQ3Bh9Wzmgb6uSxxwVF4u4m5yNsNhHCPs79NxIyEBVz/aUYkQWww0REZEB0MaILJlMQHOHBmju0AD/8nUBAPxyIQ6Lfr1S7bZJmZU/JFTbyt8RRERERKQmFxv1HkLtYGmq40r+wXBDRERENVY6IquyC1wCSkZNdfGwrbWaGG6IiIioxkpHZAEoF3BK3y8b5lWr890w3BAREdEzKR2R5WRd9tKTk7WpJA/m5A3FRERE9MxqOiJLFxhuiIiISCu0MSJLG3hZioiIiPQKww0RERHpFYYbIiIi0isMN0RERKRXGG6IiIhIrzDcEBERkV5huCEiIiK9wnBDREREeoXhhoiIiPSKwc1QLIoiACAjI0PiSmpPQUEBcnJykJGRAYVCIXU5tcZQ+w0Ybt8Ntd8A+26IfTe0fpf+3i79PV4Vgws3mZmZAAAXFxeJKyEiIiJNZWZmwtrauso2gqhOBNIjxcXFiI+Ph6WlJQSh9h/mJYWMjAy4uLggLi4OVlZWUpdTawy134Dh9t1Q+w2w74bYd0PrtyiKyMzMhLOzM2Syqu+qMbgzNzKZDE2aNJG6DElYWVkZxF+ApxlqvwHD7buh9htg3w2x74bU7+rO2JTiDcVERESkVxhuiIiISK8w3BgAExMTLFu2DCYmJlKXUqsMtd+A4fbdUPsNsO+G2HdD7bc6DO6GYiIiItJvPHNDREREeoXhhoiIiPQKww0RERHpFYYbIiIi0isMN/XYhx9+iM6dO8PS0hIODg4YMWIEbt68WeU2wcHBEASh3OvGjRu1VLV2LF++vFwfnJycqtzm2LFj8PHxgampKZo2bYqvvvqqlqrVLnd39wqP4ezZsytsX1+P+fHjxzFs2DA4OztDEATs2rWrzHpRFLF8+XI4OzvDzMwMffv2xbVr16rd72+//QYvLy+YmJjAy8sLv//+u456UHNV9b2goAD//ve/0bZtW1hYWMDZ2RkTJ05EfHx8lfvcsmVLhd+D3NxcHfdGM9Ud98mTJ5frQ7du3ardb10/7tX1u6JjJwgC/vvf/1a6z/pyzHWB4aYeO3bsGGbPno0zZ84gKCgIhYWF8Pf3R3Z2drXb3rx5EwkJCapXixYtaqFi7WrTpk2ZPly9erXStlFRURgyZAh69eqFsLAwvP3223jzzTfx22+/1WLF2nH+/Pky/Q4KCgIA/Otf/6pyu/p2zLOzs9G+fXt88cUXFa7/6KOPsHbtWnzxxRc4f/48nJycMHDgQNXz4ypy+vRpjB49GhMmTMDly5cxYcIEvPzyyzh79qyuulEjVfU9JycHoaGhePfddxEaGoqdO3fi1q1beOGFF6rdr5WVVZnvQEJCAkxNTXXRhRqr7rgDQEBAQJk+7Nu3r8p91ofjXl2/nz5umzZtgiAIeOmll6rcb3045johkt5ISkoSAYjHjh2rtM3Ro0dFAOKjR49qrzAdWLZsmdi+fXu12y9atEj09PQss+z1118Xu3XrpuXKat/cuXPFZs2aicXFxRWu14djDkD8/fffVe+Li4tFJycncfXq1aplubm5orW1tfjVV19Vup+XX35ZDAgIKLNs0KBB4pgxY7Res7Y83feKnDt3TgQgxsTEVNpm8+bNorW1tXaL07GK+j5p0iRx+PDhGu2nvh13dY758OHDxf79+1fZpj4ec23hmRs9kp6eDgCwtbWttm3Hjh2hVCoxYMAAHD16VNel6cTt27fh7OwMDw8PjBkzBnfv3q207enTp+Hv719m2aBBg3DhwgUUFBToulSdyc/Px/bt2zF16tRqHwSrD8e8VFRUFBITE8scUxMTE/Tp0wchISGVblfZ96CqbeqD9PR0CIKAhg0bVtkuKysLbm5uaNKkCZ5//nmEhYXVToFaFhwcDAcHB7Rs2RKvvvoqkpKSqmyvb8f9wYMH2Lt3L6ZNm1ZtW3055ppiuNEToihi/vz56NmzJ7y9vSttp1QqsWHDBvz222/YuXMnWrVqhQEDBuD48eO1WO2z69q1K7Zu3YqDBw/im2++QWJiIrp3746UlJQK2ycmJsLR0bHMMkdHRxQWFiI5Obk2StaJXbt2IS0tDZMnT660jb4c8yclJiYCQIXHtHRdZdtpuk1dl5ubi8WLF2PcuHFVPjzR09MTW7Zswe7du/Hjjz/C1NQUPXr0wO3bt2ux2mc3ePBgfP/99zhy5Ag++eQTnD9/Hv3790deXl6l2+jbcf/uu+9gaWmJF198scp2+nLMa8Lgngqur9544w1cuXIFJ0+erLJdq1at0KpVK9V7Pz8/xMXF4eOPP0bv3r11XabWDB48WPXntm3bws/PD82aNcN3332H+fPnV7jN02c2xL8n567ujEddtnHjRgwePBjOzs6VttGXY16Rio5pdcezJtvUVQUFBRgzZgyKi4uxfv36Ktt269atzI23PXr0QKdOnfD555/js88+03WpWjN69GjVn729veHr6ws3Nzfs3bu3yl/2+nTcN23ahFdeeaXae2f05ZjXBM/c6IE5c+Zg9+7dOHr0KJo0aaLx9t26dav3Sd7CwgJt27attB9OTk7l/i8tKSkJRkZGsLOzq40StS4mJgaHDx/G9OnTNd62vh/z0pFxFR3Tp/8P/entNN2mriooKMDLL7+MqKgoBAUFVXnWpiIymQydO3eu198DoOTMpJubW5X90KfjfuLECdy8ebNGf+/15Zirg+GmHhNFEW+88QZ27tyJI0eOwMPDo0b7CQsLg1Kp1HJ1tSsvLw8RERGV9sPPz081qqjUoUOH4OvrC4VCURslat3mzZvh4OCAoUOHarxtfT/mHh4ecHJyKnNM8/PzcezYMXTv3r3S7Sr7HlS1TV1UGmxu376Nw4cP1yigi6KIS5cu1evvAQCkpKQgLi6uyn7oy3EHSs7W+vj4oH379hpvqy/HXC3S3ctMz2rmzJmitbW1GBwcLCYkJKheOTk5qjaLFy8WJ0yYoHr/6aefir///rt469YtMTw8XFy8eLEIQPztt9+k6EKNLViwQAwODhbv3r0rnjlzRnz++edFS0tLMTo6WhTF8v2+e/euaG5uLr711lvi9evXxY0bN4oKhUL89ddfperCMykqKhJdXV3Ff//73+XW6csxz8zMFMPCwsSwsDARgLh27VoxLCxMNSJo9erVorW1tbhz507x6tWr4tixY0WlUilmZGSo9jFhwgRx8eLFqvenTp0S5XK5uHr1ajEiIkJcvXq1aGRkJJ45c6bW+1eVqvpeUFAgvvDCC2KTJk3ES5culfm7n5eXp9rH031fvny5eODAATEyMlIMCwsTp0yZIhoZGYlnz56VoouVqqrvmZmZ4oIFC8SQkBAxKipKPHr0qOjn5yc2bty43h/36r7voiiK6enporm5uRgYGFjhPurrMdcFhpt6DECFr82bN6vaTJo0SezTp4/q/Zo1a8RmzZqJpqamoo2NjdizZ09x7969tV/8Mxo9erSoVCpFhUIhOjs7iy+++KJ47do11fqn+y2KohgcHCx27NhRNDY2Ft3d3Sv9B6I+OHjwoAhAvHnzZrl1+nLMS4ewP/2aNGmSKIolw8GXLVsmOjk5iSYmJmLv3r3Fq1evltlHnz59VO1L7dixQ2zVqpWoUChET0/POhnyqup7VFRUpX/3jx49qtrH032fN2+e6OrqKhobG4v29vaiv7+/GBISUvudq0ZVfc/JyRH9/f1Fe3t7UaFQiK6uruKkSZPE2NjYMvuoj8e9uu+7KIri119/LZqZmYlpaWkV7qO+HnNdEETx77sqiYiIiPQA77khIiIivcJwQ0RERHqF4YaIiIj0CsMNERER6RWGGyIiItIrDDdERESkVxhuiIiISK8w3BCRQRIEAbt27ZK6DCLSAYYbIqp1kydPhiAI5V4BAQFSl0ZEesBI6gKIyDAFBARg8+bNZZaZmJhIVA0R6ROeuSEiSZiYmMDJyanMy8bGBkDJJaPAwEAMHjwYZmZm8PDwwI4dO8psf/XqVfTv3x9mZmaws7PDa6+9hqysrDJtNm3ahDZt2sDExARKpRJvvPFGmfXJyckYOXIkzM3N0aJFC+zevVu17tGjR3jllVdgb28PMzMztGjRolwYI6K6ieGGiOqkd999Fy+99BIuX76M8ePHY+zYsYiIiAAA5OTkICAgADY2Njh//jx27NiBw4cPlwkvgYGBmD17Nl577TVcvXoVu3fvRvPmzct8xooVK/Dyyy/jypUrGDJkCF555RWkpqaqPv/69evYv38/IiIiEBgYiEaNGtXeD4CIak7qJ3cSkeGZNGmSKJfLRQsLizKvlStXiqJY8sT7GTNmlNmma9eu4syZM0VRFMUNGzaINjY2YlZWlmr93r17RZlMJiYmJoqiKIrOzs7i0qVLK60BgPjOO++o3mdlZYmCIIj79+8XRVEUhw0bJk6ZMkU7HSaiWsV7bohIEv369UNgYGCZZba2tqo/+/n5lVnn5+eHS5cuAQAiIiLQvn17WFhYqNb36NEDxcXFuHnzJgRBQHx8PAYMGFBlDe3atVP92cLCApaWlkhKSgIAzJw5Ey+99BJCQ0Ph7++PESNGoHv37jXqKxHVLoYbIpKEhYVFuctE1REEAQAgiqLqzxW1MTMzU2t/CoWi3LbFxcUAgMGDByMmJgZ79+7F4cOHMWDAAMyePRsff/yxRjUTUe3jPTdEVCedOXOm3HtPT08AgJeXFy5duoTs7GzV+lOnTkEmk6Fly5awtLSEu7s7/vrrr2eqwd7eHpMnT8b27duxbt06bNiw4Zn2R0S1g2duiEgSeXl5SExMLLPMyMhIddPujh074Ovri549e+L777/HuXPnsHHjRgDAK6+8gmXLlmHSpElYvnw5Hj58iDlz5mDChAlwdHQEACxfvhwzZsyAg4MDBg8ejMzMTJw6dQpz5sxRq7733nsPPj4+aNOmDfLy8vDnn3+idevWWvwJEJGuMNwQkSQOHDgApVJZZlmrVq1w48YNACUjmX766SfMmjULTk5O+P777+Hl5QUAMDc3x8GDBzF37lx07twZ5ubmeOmll7B27VrVviZNmoTc3Fx8+umnWLhwIRo1aoRRo0apXZ+xsTGWLFmC6OhomJmZoVevXvjpp5+00HMi0jVBFEVR6iKIiJ4kCAJ+//13jBgxQupSiKge4j03REREpFcYboiIiEiv8J4bIqpzeLWciJ4Fz9wQERGRXmG4ISIiIr3CcENERER6heGGiIiI9ArDDREREekVhhsiIiLSKww3REREpFcYboiIiEivMNwQERGRXvl/PM+rEwIaOuYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = list(range(1, 20))\n",
    "loss_values = [\n",
    "    0.6690408940217933, 0.5850774889089623, 0.5253639409736711, 0.448875014271055,\n",
    "    0.4460091006999113, 0.38000536208250085, 0.33870953078172644, 0.3191174469432052,\n",
    "    0.30293984133370067, 0.2937456564027436, 0.2821461080896611, 0.25704940971063106,\n",
    "    0.2449793216525292, 0.23558637864735663, 0.271874051313011, 0.24400102818498806,\n",
    "    0.19991839449016416, 0.1902288554274306, 0.18227853793270735\n",
    "]\n",
    "\n",
    "plt.plot(epochs, loss_values, marker='o')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Binary Cross Entropy Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-541448256856/pytorch-training-2023-12-13-18-21-37-175/output/model.tar.gz), script artifact (s3://sagemaker-us-east-1-541448256856/pytorch-training-2023-12-13-18-21-37-175/source/sourcedir.tar.gz), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-541448256856/pytorch-training-2023-12-13-22-35-46-064/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-training-2023-12-13-22-35-46-064\n",
      "INFO:sagemaker:Creating endpoint-config with name pytorch-training-2023-12-13-22-35-46-064\n",
      "INFO:sagemaker:Creating endpoint with name pytorch-training-2023-12-13-22-35-46-064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "# TODO: Deploy the trained model\n",
    "estimator_predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = pd.concat([pd.DataFrame(test_X_len), pd.DataFrame(test_X)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, rows=512):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = np.array([])\n",
    "    for array in split_array:\n",
    "        predictions = np.append(predictions, estimator_predictor.predict(array))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(test_X.values)\n",
    "predictions = [round(num) for num in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8496"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = 'The simplest pleasures in life are the best, and this film is one of them. Combining a rather basic storyline of love and adventure this movie transcends the usual weekend fair with wit and unmitigated charm.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review_X, test_review_len = convert_and_pad(word_dict, review_to_words(test_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.hstack((test_review_len, test_review_X))\n",
    "test_data = test_data.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 501)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.98979938)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_predictor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:The function delete_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "estimator.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# import argparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# import json\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# import os\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# import pickle\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# import sys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# import pandas as pd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# import numpy as np\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# import torch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# import torch.nn as nn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# import torch.optim as optim\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# import torch.utils.data\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# from model import LSTMClassifier\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# from utils import review_to_words, convert_and_pad\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# def model_fn(model_dir):\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     \"\"\"Load the PyTorch model from the `model_dir` directory.\"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     print(\"Loading model.\")\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     # First, load the parameters used to create the model.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     model_info = {}\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     model_info_path = os.path.join(model_dir, 'model_info.pth')\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     with open(model_info_path, 'rb') as f:\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#         model_info = torch.load(f)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     print(\"model_info: {}\".format(model_info))\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     # Determine the device and construct the model.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     model = LSTMClassifier(model_info['embedding_dim'], model_info['hidden_dim'], model_info['vocab_size'])\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     # Load the store model parameters.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     model_path = os.path.join(model_dir, 'model.pth')\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     with open(model_path, 'rb') as f:\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#         model.load_state_dict(torch.load(f))\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     # Load the saved word_dict.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     word_dict_path = os.path.join(model_dir, 'word_dict.pkl')\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     with open(word_dict_path, 'rb') as f:\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#         model.word_dict = pickle.load(f)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     model.to(device).eval()\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     print(\"Done loading model.\")\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     return model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# def input_fn(serialized_input_data, content_type):\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     print('Deserializing the input data.')\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     if content_type == 'text/plain':\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#         data = serialized_input_data.decode('utf-8')\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#         return data\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     raise Exception('Requested unsupported ContentType in content_type: ' + content_type)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# def output_fn(prediction_output, accept):\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     print('Serializing the generated output.')\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     return str(prediction_output)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# def predict_fn(input_data, model):\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     print('Inferring sentiment of input data.')\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     if model.word_dict is None:\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#         raise Exception('Model has not been loaded properly, no word_dict.')\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     # TODO: Process input_data so that it is ready to be sent to our model.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     #       You should produce two variables:\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     #         data_X   - A sequence of length 500 which represents the converted review\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     #         data_len - The length of the review\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     data_X = None\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     data_len = None\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     data_X, data_len = convert_and_pad(model.word_dict, review_to_words(input_data))\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     # Using data_X and data_len we construct an appropriate input tensor. Remember\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     # that our model expects input data of the form 'len, review[500]'.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     data_pack = np.hstack((data_len, data_X))\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     data_pack = data_pack.reshape(1, -1)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     data = torch.from_numpy(data_pack)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     data = data.to(device)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     # Make sure to put the model into evaluation mode\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     model.eval()\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     # TODO: Compute the result of applying the model to the input data. The variable `result` should\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     #       be a numpy array which contains a single integer which is either 1 or 0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     with torch.no_grad():\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#         output = model.forward(data)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     result = np.round(output.numpy())\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     return result\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmodel\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LSTMClassifier\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mutils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m review_to_words, convert_and_pad\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[33m\"\"\"Load the PyTorch model from the `model_dir` directory.\"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# First, load the parameters used to create the model.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    model_info = {}\u001b[37m\u001b[39;49;00m\r\n",
      "    model_info_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_info.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_info_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\u001b[37m\u001b[39;49;00m\r\n",
      "        model_info = torch.load(f)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_info: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(model_info))\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# Determine the device and construct the model.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    model = LSTMClassifier(model_info[\u001b[33m'\u001b[39;49;00m\u001b[33membedding_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], model_info[\u001b[33m'\u001b[39;49;00m\u001b[33mhidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], model_info[\u001b[33m'\u001b[39;49;00m\u001b[33mvocab_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# Load the stored model parameters.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    model_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\u001b[37m\u001b[39;49;00m\r\n",
      "        model.load_state_dict(torch.load(f, map_location=device))  \u001b[37m# Added map_location to ensure compatibility\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# Load the saved word_dict.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    word_dict_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mword_dict.pkl\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(word_dict_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\u001b[37m\u001b[39;49;00m\r\n",
      "        model.word_dict = pickle.load(f)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    model.to(device).eval()\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDone loading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# def input_fn(serialized_input_data, content_type):\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     print('Deserializing the input data.')\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     if content_type == 'text/plain':\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#         data = serialized_input_data.decode('utf-8')\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#         return data\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m#     raise Exception('Requested unsupported ContentType in content_type: ' + content_type)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(serialized_input_data, content_type):\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mDeserializing the input data.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mif\u001b[39;49;00m content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mtext/plain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\r\n",
      "        data = serialized_input_data.decode(\u001b[33m'\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m data\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34melif\u001b[39;49;00m content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/octet-stream\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[37m# Assuming the input data is binary, you can convert it to text\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "        data = serialized_input_data.decode(\u001b[33m'\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m data\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mRequested unsupported ContentType: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcontent_type\u001b[33m}\u001b[39;49;00m\u001b[33m. Returning empty data.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(prediction_output, accept):\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mSerializing the generated output.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m \u001b[36mstr\u001b[39;49;00m(prediction_output)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_data, model):\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mInferring sentiment of input data.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mif\u001b[39;49;00m model.word_dict \u001b[35mis\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mModel has not been loaded properly, no word_dict.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# TODO: Process input_data so that it is ready to be sent to our model.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m#       You should produce two variables:\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m#         data_X   - A sequence of length 500 that represents the converted review\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m#         data_len - The length of the review\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    data_X, data_len = convert_and_pad(model.word_dict, review_to_words(input_data))\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# Using data_X and data_len, we construct an appropriate input tensor. Remember\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# that our model expects input data of the form 'len, review[500]'.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    data_pack = np.hstack((data_len, data_X))\u001b[37m\u001b[39;49;00m\r\n",
      "    data_pack = data_pack.reshape(\u001b[34m1\u001b[39;49;00m, -\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    data = torch.from_numpy(data_pack)\u001b[37m\u001b[39;49;00m\r\n",
      "    data = data.to(device)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# Make sure to put the model into evaluation mode\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    model.eval()\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# TODO: Compute the result of applying the model to the input data. The variable `result` should\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m#       be a numpy array that contains a single integer, either 1 or 0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\u001b[37m\u001b[39;49;00m\r\n",
      "        output = model.forward(data)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    result = np.round(output.numpy())\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m result\u001b[37m\u001b[39;49;00m\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize serve/predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-541448256856/pytorch-training-2023-12-13-18-21-37-175/output/model.tar.gz), script artifact (serve), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-541448256856/pytorch-inference-2023-12-13-22-46-42-576/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2023-12-13-22-46-43-512\n",
      "INFO:sagemaker:Creating endpoint-config with name pytorch-inference-2023-12-13-22-46-44-172\n",
      "INFO:sagemaker:Creating endpoint with name pytorch-inference-2023-12-13-22-46-44-172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:The class RealTimePredictor has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:content_type is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import RealTimePredictor\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "class StringPredictor(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(StringPredictor, self).__init__(endpoint_name, sagemaker_session, content_type='text/plain')\n",
    "\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role = role,\n",
    "                     framework_version='1.8.1',\n",
    "                     py_version=\"py3\",   \n",
    "                     entry_point='predict.py',\n",
    "                     source_dir='serve',\n",
    "                     predictor_cls=StringPredictor)\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reviews(predictor, data_dir='../data/aclImdb', stop=250):\n",
    "    results = []\n",
    "    ground = []\n",
    "\n",
    "    for sentiment in ['pos', 'neg']:\n",
    "        path = os.path.join(data_dir, 'test', sentiment, '*.txt')\n",
    "        files = glob.glob(path)\n",
    "\n",
    "        files_read = 0\n",
    "\n",
    "        print('Starting ', sentiment, ' files')\n",
    "\n",
    "        for f in files:\n",
    "            with open(f) as review:\n",
    "                if sentiment == 'pos':\n",
    "                    ground.append(1)\n",
    "                else:\n",
    "                    ground.append(0)\n",
    "                review_input = review.read().encode('utf-8')\n",
    "                results.append(float(predictor.predict(review_input)))\n",
    "\n",
    "            files_read += 1\n",
    "            if files_read == stop:\n",
    "                break\n",
    "\n",
    "    return ground, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:The class RealTimePredictor has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:content_type is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "Starting  pos  files\n",
      "Starting  neg  files\n"
     ]
    }
   ],
   "source": [
    "accept_header = 'text/plain'  # Specify the expected response content type\n",
    "endpoint_name = 'pytorch-inference-2023-12-13-22-46-44-172'  # Replace with your actual endpoint name\n",
    "predictor = sagemaker.predictor.RealTimePredictor(endpoint_name=endpoint_name, content_type=accept_header)\n",
    "\n",
    "ground, results = test_reviews(predictor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ground, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.77      0.84       250\n",
      "           1       0.80      0.93      0.86       250\n",
      "\n",
      "    accuracy                           0.85       500\n",
      "   macro avg       0.86      0.85      0.85       500\n",
      "weighted avg       0.86      0.85      0.85       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ground, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'1.0'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'pytorch-inference-2023-12-13-22-46-44-172'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
